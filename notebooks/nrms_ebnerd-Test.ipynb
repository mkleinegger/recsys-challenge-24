{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:58:44.274226Z",
     "start_time": "2024-05-18T16:58:39.936186Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ebnerd-benchmark' already exists and is not an empty directory.\n",
      "Requirement already satisfied: polars in /opt/conda/lib/python3.11/site-packages (0.20.8)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.37.2)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: polars in /opt/conda/lib/python3.11/site-packages (0.20.8)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "#Cloning our ebrec\n",
    "!git clone https://github.com/ebanalyse/ebnerd-benchmark.git\n",
    "\n",
    "#Poetry\n",
    "#!curl -sSL https://install.python-poetry.org | python3\n",
    "#!python3 -m poetry shell\n",
    "#!python3 -m poetry add ebrec\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Pip\n",
    "#!pip install ebrec\n",
    "!pip install polars\n",
    "!pip install transformers tensorflow polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/e12242664/shared/194.035-2024S/groups/Gruppe_33/Group_33/notebooks/ebnerd-benchmark\n",
      "Processing /home/e12242664/shared/194.035-2024S/groups/Gruppe_33/Group_33/notebooks/ebnerd-benchmark\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<4.37.3,>=4.30.0 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (4.37.2)\n",
      "Requirement already satisfied: tensorflow<2.16.0,>=2.12.0 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (2.15.0)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (2.1.2+cu121)\n",
      "Requirement already satisfied: scikit-learn==1.4.0 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (1.4.0)\n",
      "Requirement already satisfied: numpy<1.26.1,>=1.24.0 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (1.26.0)\n",
      "Requirement already satisfied: polars==0.20.8 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (0.20.8)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (4.66.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0->ebrec==0.0.1) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0->ebrec==0.0.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0->ebrec==0.0.1) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (4.10.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (3.13.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (0.22.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (0.4.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<2.3.0,>=2.0.0->ebrec==0.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch<2.3.0,>=2.0.0->ebrec==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.2.2)\n",
      "Building wheels for collected packages: ebrec\n",
      "  Building wheel for ebrec (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ebrec: filename=ebrec-0.0.1-py3-none-any.whl size=74959 sha256=2b07ab28c76ae110be316b2a22c4a86e6fc3918b52c5e949e0206ca5e3be9bea\n",
      "  Stored in directory: /home/e12242664/.cache/pip/wheels/22/47/12/787bb533bf4f700aa706795302157e360ad5c00bf4b20db395\n",
      "Successfully built ebrec\n",
      "Installing collected packages: ebrec\n",
      "  Attempting uninstall: ebrec\n",
      "    Found existing installation: ebrec 0.0.1\n",
      "    Uninstalling ebrec-0.0.1:\n",
      "      Successfully uninstalled ebrec-0.0.1\n",
      "Successfully installed ebrec-0.0.1\n"
     ]
    }
   ],
   "source": [
    "%cd ebnerd-benchmark\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:58:47.920171Z",
     "start_time": "2024-05-18T16:58:47.839314Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 13:58:17.305224: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-20 13:58:17.353559: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-20 13:58:17.353613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-20 13:58:17.355391: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-20 13:58:17.365190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 13:58:18.397105: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "   DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "   DEFAULT_CLICKED_ARTICLES_COL,\n",
    "   DEFAULT_INVIEW_ARTICLES_COL,\n",
    "   DEFAULT_IMPRESSION_ID_COL,\n",
    "   DEFAULT_SUBTITLE_COL,\n",
    "   DEFAULT_LABELS_COL,\n",
    "   DEFAULT_TITLE_COL,\n",
    "   DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "\n",
    "#\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "\n",
    "#\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "\n",
    "#\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "article_ids_clicked\n\nError originated just after this operation:\nDF [\"impression_id\", \"impression_time\", \"read_time\", \"scroll_percentage\"]; PROJECT */15 COLUMNS; SELECTION: \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m HISTORY_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      9\u001b[0m N_SAMPLES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     10\u001b[0m df_train \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     11\u001b[0m     \u001b[43mebnerd_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHISTORY_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCOLUMNS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mpipe(\n\u001b[1;32m     14\u001b[0m         sampling_strategy_wu2019,\n\u001b[1;32m     15\u001b[0m         npratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     16\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m         with_replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m         seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m,\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;241m.\u001b[39mpipe(create_binary_labels_column)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mN_SAMPLES)\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# =>\u001b[39;00m\n\u001b[1;32m     24\u001b[0m df_validation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     25\u001b[0m     ebnerd_from_path(path\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m), history_size\u001b[38;5;241m=\u001b[39mHISTORY_SIZE)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(COLUMNS)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;241m.\u001b[39mpipe(create_binary_labels_column)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mN_SAMPLES)\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/polars/dataframe/frame.py:8128\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   8028\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\n\u001b[1;32m   8029\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr\n\u001b[1;32m   8030\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8031\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   8032\u001b[0m \u001b[38;5;124;03m    Select columns from this DataFrame.\u001b[39;00m\n\u001b[1;32m   8033\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8126\u001b[0m \u001b[38;5;124;03m    └───────────┘\u001b[39;00m\n\u001b[1;32m   8127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/polars/lazyframe/frame.py:1935\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, background, _eager)\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m background:\n\u001b[1;32m   1933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InProcessQuery(ldf\u001b[38;5;241m.\u001b[39mcollect_concurrently())\n\u001b[0;32m-> 1935\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(ldf\u001b[38;5;241m.\u001b[39mcollect())\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: article_ids_clicked\n\nError originated just after this operation:\nDF [\"impression_id\", \"impression_time\", \"read_time\", \"scroll_percentage\"]; PROJECT */15 COLUMNS; SELECTION: \"None\""
     ]
    }
   ],
   "source": [
    "path = Path (\"/home/e12242664/shared/194.035-2024S/groups/Gruppe_33/Group_33/downloads/test\")\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "]\n",
    "HISTORY_SIZE = 20\n",
    "N_SAMPLES = 10\n",
    "df_train = (\n",
    "    ebnerd_from_path(path.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(n=N_SAMPLES)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(path.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(n=N_SAMPLES)\n",
    ")\n",
    "# =>\n",
    "df_test = (\n",
    "    ebnerd_from_path(path.joinpath(\"test\"), history_size=HISTORY_SIZE)\n",
    "    .with_columns(pl.Series(DEFAULT_CLICKED_ARTICLES_COL, [[]]))\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(n=N_SAMPLES)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the difference between Training/Validation and Testset\n",
    "Note, the testset doesn't include labels, and we have remove some of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pl.read_parquet(path.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.6102\n",
      "Epoch 1: val_loss improved from inf to 0.00000, saving model to downloads/data/state_dict/NRMS/weights.weights.h5\n",
      "1/1 [==============================] - 19s 19s/step - loss: 1.6102 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = f\"downloads/data/state_dict/{MODEL_NAME}/weights.weights.h5\"\n",
    "\n",
    "# CALLBACKS\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=1,\n",
    "    callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    ")\n",
    "model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 809ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_validation = model.scorer.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>labels</th><th>scores</th><th>is_known_user</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>list[i8]</td><td>list[f64]</td><td>bool</td></tr></thead><tbody><tr><td>1583352</td><td>[9778628, 9778351, … 9778939]</td><td>[9754241, 9781636, … 9781467]</td><td>[9779411]</td><td>[0, 0, … 0]</td><td>[0.500122, 0.501357, … 0.501571]</td><td>false</td></tr><tr><td>521886</td><td>[9769450, 9769433, … 9778110]</td><td>[9778155, 9772882, … 9780476]</td><td>[9780195]</td><td>[0, 0, … 0]</td><td>[0.499605, 0.498464, … 0.499788]</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬─────────────┬──────────────┬──────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      ┆ scores       ┆ is_known_use │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ ---         ┆ ---          ┆ r            │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    ┆ list[f64]    ┆ ---          │\n",
       "│         ┆ list[i32]    ┆ list[i32]    ┆ list[i32]    ┆             ┆              ┆ bool         │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪═════════════╪══════════════╪══════════════╡\n",
       "│ 1583352 ┆ [9778628,    ┆ [9754241,    ┆ [9779411]    ┆ [0, 0, … 0] ┆ [0.500122,   ┆ false        │\n",
       "│         ┆ 9778351, …   ┆ 9781636, …   ┆              ┆             ┆ 0.501357, …  ┆              │\n",
       "│         ┆ 9778939]     ┆ 9781467]     ┆              ┆             ┆ 0.501571]    ┆              │\n",
       "│ 521886  ┆ [9769450,    ┆ [9778155,    ┆ [9780195]    ┆ [0, 0, … 0] ┆ [0.499605,   ┆ false        │\n",
       "│         ┆ 9769433, …   ┆ 9772882, …   ┆              ┆             ┆ 0.498464, …  ┆              │\n",
       "│         ┆ 9778110]     ┆ 9780476]     ┆              ┆             ┆ 0.499788]    ┆              │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴─────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "    add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    ")\n",
    "df_validation.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.6156245421245421,\n",
       "    \"mrr\": 0.35690836940836934,\n",
       "    \"ndcg@5\": 0.3261859507142915,\n",
       "    \"ndcg@10\": 0.3910657717261977\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "\n",
    "metrics = MetricEvaluator(\n",
    "    labels=df_validation[\"labels\"].to_list(),\n",
    "    predictions=df_validation[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.scorer.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
