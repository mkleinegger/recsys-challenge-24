{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTUR: Long- and Short-term User Representation for News Recommendation\n",
    "\n",
    "This notebook contains code for training and testing a LSTUR model on the Ebnerd Dataset. This notebook is implemented based on the LSTURDataLoader, LSTURModel and the NRMS example notebook in the Ebnerd Benchmark Repository \\[1\\].\n",
    "\n",
    "LSTUR \\[2\\] is a news recommendation approach that captures users' both long-term preferences and short-term interests. The core of LSTUR is composed of a news encoder and a user encoder. The news encoder learns representations of news from their titles, while the user encoder learns long-term user representations from the embeddings of their IDs and short-term user representations from their recently browsed news via a GRU network.\n",
    "\n",
    "## Properties of LSTUR:\n",
    "\n",
    "- **Dual User Representations**: LSTUR captures both short-term and long-term preferences by using embeddings of users' IDs for long-term user representations and a GRU network to learn short-term user representations from recently browsed articles.\n",
    "- **News Encoder**: Utilizes the news titles to generate news representations.\n",
    "- **User Encoder**: Combines long-term and short-term user representations. Two methods are proposed for this combination:\n",
    "  - Initializing the hidden state of the GRU network with the long-term user representation.\n",
    "  - Concatenating both long-term and short-term user representations to form a unified user vector.\n",
    " \n",
    "\\[1\\] https://github.com/ebanalyse/ebnerd-benchmark\n",
    "\n",
    "\\[2\\] https://aclanthology.org/P19-1033/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import LSTURDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_lstur\n",
    "from ebrec.models.newsrec import LSTURModel\n",
    "\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Behavior and History Parquet Files\n",
    "The functions below are necessary for transforming the Ebnerd Dataset tables (`history.parquet` and `behaviors.parquet`) into a format suitable for training and testing. This transformation is achieved by joining the histories and behaviors based on the `user ID`. Additionally, preprocessing steps are performed, such as truncating the user history to keep only the specified `history_size`. The `ebnerd_from_path_lazy` function is specifically designed for loading the large testset to avoid impractical memory usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd dataset and join history with behaviors.\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "def ebnerd_from_path_lazy(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd dataset and join history with behaviors\n",
    "    in a lazy fashion.\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "    )\n",
    "    return df_behaviors.join(other=df_history, on=DEFAULT_USER_COL, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Path and Data Configuration\n",
    "Here we setup the `PATH` to the ebenrd dataset we are using for training. `COLUMNS` define the columns we are using for the model training, `TEXT_COLUMNS_TO_USE` contains columns should be considered in the embedding process. The other constants define \"optimal\" model paramter which has been found throughout a hyperopt process, look into `lstur-hyperopt.ipynb` and `lstur-analysis.ipynb` for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"LSTUR\"\n",
    "MODEL_PATH = Path.home() / \"shared/194.035-2024S/groups/Gruppe_33/Group_33/models\" / MODEL_NAME\n",
    "MODEL_WEIGHTS = MODEL_PATH / \"weights\"\n",
    "DATA_PATH = Path.home() / \"shared/194.035-2024S/groups/Gruppe_33/Group_33/downloads\"\n",
    "DATASPLIT = \"small\"\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "\n",
    "TITLE_LENGTH = 50\n",
    "HISTORY_SIZE = 100\n",
    "NUSER_SIZE = 70000\n",
    "DROPOUT = 0.5 \n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "TRIAN_ON_TESTSET = False\n",
    "TRAIN_MODEL = os.environ.get(\"TRAIN\")\n",
    "\n",
    "FRACTION = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Process Training and Validation Data\n",
    "This section uses the previously defined functions to create training and validation datasets. Additional preprocessing steps include applying the `sampling_strategy_wu2019` strategy, creating binary labels using `create_binary_labels_column`, and sampling a fraction of the data for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = (\n",
    "    ebnerd_from_path(DATA_PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "df_validation = (\n",
    "    ebnerd_from_path(DATA_PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "df_validation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Articles\n",
    "In this cell we are loading the articles into memory which will later be used for the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pl.read_parquet(DATA_PATH.joinpath(DATASPLIT, \"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and Configure Transformer Model\n",
    "\n",
    "This cell loads a pre-trained transformer model and tokenizer from Hugging Face, specifically FacebookAI/xlm-roberta-base, establishing the NLP backbone for the notebook. The transformer model is critical for transforming raw text data into structured embeddings that can be effectively utilized within the recommendation system. The following steps are executed:\n",
    "- **Load Transformer Model and Tokenizer**: The AutoModel and AutoTokenizer from Hugging Face are used to load the pre-trained xlm-roberta-base model.\n",
    "- **Initialize Word Embeddings**: Word embeddings are initialized using the transformer's word embeddings to enhance the text representation.\n",
    "- **Concatenate Text Columns**: Text columns from the articles dataframe are concatenated to create a comprehensive text field.\n",
    "- **Convert Text to Encodings**: The concatenated text is tokenized and converted to numerical encodings using the transformer tokenizer, with a specified maximum length.\n",
    "- **Create Article Mapping**: A mapping from article IDs to their corresponding tokenized values is created, facilitating efficient lookup and processing in the recommendation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the LSTUR Model\n",
    "The following cells handle the setup and training of the LSTUR model. If `TRAIN_MODEL` is `True`, the necessary data loaders are created, the model is configured with specific hyperparameters, and the training process begins. If `TRAIN_MODEL` is `False`, the pre-trained model weights are loaded instead.\n",
    "\n",
    "### Data Loading for Model Input and Model Configuration\n",
    "This cell creates data loaders for both training and validation. A mapping from user IDs to unique integer indices is created to facilitate embedding lookup. The `LSTURDataLoader` is initialized for both training and validation datasets, handling batching, shuffling, and input feature construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_mapping = {user_id: i for i, user_id in enumerate(df_train[DEFAULT_USER_COL].unique())}\n",
    "\n",
    "train_dataloader = LSTURDataLoader(\n",
    "    user_id_mapping=user_id_mapping,\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=5,\n",
    ")\n",
    "val_dataloader = LSTURDataLoader(\n",
    "    user_id_mapping=user_id_mapping,\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Configuration\n",
    "If `TRAIN_MODEL` is `True`, this cell sets up the LSTUR model with specific hyperparameters and begins training. It configures paths for logging and saving model weights, and sets up callbacks for TensorBoard logging, early stopping, and model checkpointing. The LSTUR model is then trained using the training DataLoader and validated using the validation DataLoader. If `TRAIN_MODEL` is `False`, the model weights are loaded from the specified path instead of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    LOG_DIR = f\"tmp/runs/{MODEL_NAME}\"\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "    modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    "    )\n",
    "    \n",
    "    hparams_lstur.history_size = HISTORY_SIZE\n",
    "    hparams_lstur.title_size = TITLE_LENGTH\n",
    "    hparams_lstur.n_users = NUSER_SIZE\n",
    "    hparams_lstur.dropout = DROPOUT\n",
    "    hparams_lstur.learning_rate = LEARNING_RATE\n",
    "    \n",
    "    model = LSTURModel(\n",
    "        hparams=hparams_lstur,\n",
    "        word2vec_embedding=word2vec_embedding,\n",
    "        seed=42,\n",
    "    )\n",
    "    hist = model.model.fit(\n",
    "        train_dataloader,\n",
    "        validation_data=val_dataloader,\n",
    "        epochs=1,\n",
    "        callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    "    )\n",
    "\n",
    "hparams_lstur.history_size = HISTORY_SIZE\n",
    "hparams_lstur.title_size = TITLE_LENGTH\n",
    "hparams_lstur.n_users = NUSER_SIZE\n",
    "hparams_lstur.dropout = DROPOUT\n",
    "hparams_lstur.learning_rate = LEARNING_RATE\n",
    "\n",
    "model = LSTURModel(\n",
    "    hparams=hparams_lstur,\n",
    "    word2vec_embedding=word2vec_embedding\n",
    ")\n",
    "_ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the Trained Model\n",
    "\n",
    "The following cells evaluate the trained LSTUR model either on the test set or the validation set. If `TESTSET` is set to `True`, the evaluation is performed on the test set; otherwise, it is performed on the validation set. This process includes loading and preprocessing the data, making predictions with the model, calculating performance metrics, ranking predictions, and optionally writing the results to a submission file.\n",
    "\n",
    "### Load and Preprocess the Test or Validation Data\n",
    "This cell loads and preprocesses the data for evaluation. If `TESTSET` is `True`, it loads the test dataset, adds a column for clicked articles (initially empty), selects the required columns, creates binary labels, and samples a fraction of the dataset for efficiency. It then initializes the `LSTURDataLoader` for the test data. If `TESTSET` is `False`, it uses the previously initialized `val_dataloader` for validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRIAN_ON_TESTSET:\n",
    "    df_test = (\n",
    "        ebnerd_from_path_lazy(DATA_PATH.joinpath(\"test\"), history_size=HISTORY_SIZE)\n",
    "        .with_columns(pl.Series(DEFAULT_CLICKED_ARTICLES_COL, [[]]))\n",
    "        .select(COLUMNS)\n",
    "        .pipe(create_binary_labels_column)\n",
    "        .collect()\n",
    "        .sample(fraction=FRACTION)\n",
    "    )\n",
    "    \n",
    "    test_dataloader = LSTURDataLoader(\n",
    "        user_id_mapping=user_id_mapping,\n",
    "        behaviors=df_test,\n",
    "        article_dict=article_mapping,\n",
    "        unknown_representation=\"zeros\",\n",
    "        history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "        eval_mode=True,\n",
    "        batch_size=5,\n",
    "    )\n",
    "\n",
    "    print(df_test.head(2))\n",
    "    \n",
    "else:\n",
    "    test_dataloader = val_dataloader\n",
    "    df_test = df_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performs prediction\n",
    "This cell uses the trained model to make predictions on the test or validation data. The `predict` method of the model scorer is applied to the `test_dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.scorer.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = add_prediction_scores(df_test, pred_test.tolist()).pipe(\n",
    "    add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    ")\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Prediction Performance\n",
    "This cell evaluates the model's performance using the metrics: AUC, MRR, and NDCG (5 and 10). The `MetricEvaluator` class is initialized with the true labels and prediction scores, and the evaluation is performed using the specified metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_test[\"labels\"].to_list(),\n",
    "    predictions=df_test[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Predictions by Score\n",
    "This cell ranks the predictions by their scores. It adds a new column `ranked_scores` to the dataframe, where the predictions are ranked based on their scores using the `rank_predictions_by_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.with_columns(\n",
    "    pl.col(\"scores\")\n",
    "    .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "    .alias(\"ranked_scores\")\n",
    ")\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Submission File\n",
    "This cell writes the ranked predictions to a submission file. The `write_submission_file` function takes the impression IDs and ranked prediction scores from the dataframe and writes them to the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(\n",
    "    impression_ids=df_test[DEFAULT_IMPRESSION_ID_COL],\n",
    "    prediction_scores=df_test[\"ranked_scores\"],\n",
    "    path=f\"{MODEL_PATH}/predictions.txt\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g33",
   "language": "python",
   "name": "g33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
