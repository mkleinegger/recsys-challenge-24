{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:58:44.274226Z",
     "start_time": "2024-05-18T16:58:39.936186Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:58:47.920171Z",
     "start_time": "2024-05-18T16:58:47.839314Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 15:49:10.033369: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-20 15:49:10.090671: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-20 15:49:10.090731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-20 15:49:10.094643: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-20 15:49:10.113089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 15:49:11.123009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "   DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "   DEFAULT_CLICKED_ARTICLES_COL,\n",
    "   DEFAULT_INVIEW_ARTICLES_COL,\n",
    "   DEFAULT_IMPRESSION_ID_COL,\n",
    "   DEFAULT_SUBTITLE_COL,\n",
    "   DEFAULT_LABELS_COL,\n",
    "   DEFAULT_TITLE_COL,\n",
    "   DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "\n",
    "#\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "\n",
    "#\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "\n",
    "#\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/home/e12242664/shared/194.035-2024S/groups/Gruppe_33/Group_33/downloads\")\n",
    "DATASPLIT = \"demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>172491</td><td>[9770989, 9769553, … 9763284]</td><td>[9778623, 9052240, … 9778448]</td><td>[9777026]</td><td>510006864</td><td>[0, 0, … 0]</td></tr><tr><td>2498205</td><td>[9767363, 9767417, … 9769404]</td><td>[9778745, 9778657, … 9778718]</td><td>[9778657]</td><td>378657114</td><td>[0, 1, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 172491  ┆ [9770989,         ┆ [9778623,         ┆ [9777026]        ┆ 510006864     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9769553, …        ┆ 9052240, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9763284]          ┆ 9778448]          ┆                  ┆               ┆             │\n",
       "│ 2498205 ┆ [9767363,         ┆ [9778745,         ┆ [9778657]        ┆ 378657114     ┆ [0, 1, … 0] │\n",
       "│         ┆ 9767417, …        ┆ 9778657, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9769404]          ┆ 9778718]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 10\n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "df_test = (ebnerd_from_path(PATH.joinpath(\"test\"), history_size=HISTORY_SIZE)\n",
    "    .select([\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "])\n",
    "  \n",
    "    .sample(fraction=FRACTION)\n",
    "          )\n",
    "    \n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the difference between Training/Validation and Testset\n",
    "Note, the testset doesn't include labels, and we have remove some of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>172491</td><td>[9770989, 9769553, … 9763284]</td><td>[9778623, 9052240, … 9778448]</td><td>[9777026]</td><td>510006864</td><td>[0, 0, … 0]</td></tr><tr><td>2498205</td><td>[9767363, 9767417, … 9769404]</td><td>[9778745, 9778657, … 9778718]</td><td>[9778657]</td><td>378657114</td><td>[0, 1, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 172491  ┆ [9770989,         ┆ [9778623,         ┆ [9777026]        ┆ 510006864     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9769553, …        ┆ 9052240, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9763284]          ┆ 9778448]          ┆                  ┆               ┆             │\n",
       "│ 2498205 ┆ [9767363,         ┆ [9778745,         ┆ [9778657]        ┆ 378657114     ┆ [0, 1, … 0] │\n",
       "│         ┆ 9767417, …        ┆ 9778657, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9769404]          ┆ 9778718]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>impression_id</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>u32</td></tr></thead><tbody><tr><td>162665</td><td>[9789475, 9790548, … 9789674]</td><td>[9794282, 9737023, … 9796687]</td><td>552223303</td></tr><tr><td>2140627</td><td>[9790025, 9789704, … 9790548]</td><td>[9800148, 9799778, … 9799773]</td><td>511998028</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌─────────┬───────────────────────────────┬───────────────────────────────┬───────────────┐\n",
       "│ user_id ┆ article_id_fixed              ┆ article_ids_inview            ┆ impression_id │\n",
       "│ ---     ┆ ---                           ┆ ---                           ┆ ---           │\n",
       "│ u32     ┆ list[i32]                     ┆ list[i32]                     ┆ u32           │\n",
       "╞═════════╪═══════════════════════════════╪═══════════════════════════════╪═══════════════╡\n",
       "│ 162665  ┆ [9789475, 9790548, … 9789674] ┆ [9794282, 9737023, … 9796687] ┆ 552223303     │\n",
       "│ 2140627 ┆ [9790025, 9789704, … 9790548] ┆ [9800148, 9799778, … 9799773] ┆ 511998028     │\n",
       "└─────────┴───────────────────────────────┴───────────────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3037230</td><td>&quot;Ishockey-spill…</td><td>&quot;ISHOCKEY: Isho…</td><td>2023-06-29 06:20:57</td><td>false</td><td>&quot;Ambitionerne o…</td><td>2003-08-28 08:55:00</td><td>null</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Mindre ulykke&quot;]</td><td>142</td><td>[327, 334]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr><tr><td>3044020</td><td>&quot;Prins Harry tv…</td><td>&quot;Hoffet tvang P…</td><td>2023-06-29 06:21:16</td><td>false</td><td>&quot;Den britiske t…</td><td>2005-06-29 08:47:00</td><td>[3097307, 3097197, 3104927]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Harry&quot;, &quot;James Hewitt&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Personfarlig kriminalitet&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7084</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3037230   ┆ Ishockey- ┆ ISHOCKEY: ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ spiller:  ┆ Ishockey- ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Jeg       ┆ spilleren ┆ 06:20:57  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ troede    ┆ Seb…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ jeg…      ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3044020   ┆ Prins     ┆ Hoffet    ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7084    ┆ Negative │\n",
       "│           ┆ Harry     ┆ tvang     ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tvunget   ┆ Prins     ┆ 06:21:16  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ til       ┆ Harry til ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dna-test  ┆ at …      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(DATASPLIT, \"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 16:02:01.543498: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 350.24MiB (rounded to 367248384)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-06-20 16:02:01.543594: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-06-20 16:02:01.543612: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 7, Chunks in use: 6. 1.8KiB allocated for chunks. 1.5KiB in use in bin. 56B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543619: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543625: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543631: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543636: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543641: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543645: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543650: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543654: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543659: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543664: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543668: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543673: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543678: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543682: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543687: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543691: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543702: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543708: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543716: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543723: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 700.62MiB allocated for chunks. 700.62MiB in use in bin. 700.47MiB client-requested in use in bin.\n",
      "2024-06-20 16:02:01.543729: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 350.24MiB was 256.00MiB, Chunk State: \n",
      "2024-06-20 16:02:01.543743: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 734658560\n",
      "2024-06-20 16:02:01.543751: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f494c000000 of size 1280 next 1\n",
      "2024-06-20 16:02:01.543755: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f494c000500 of size 256 next 2\n",
      "2024-06-20 16:02:01.543759: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f494c000600 of size 256 next 3\n",
      "2024-06-20 16:02:01.543763: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f494c000700 of size 256 next 5\n",
      "2024-06-20 16:02:01.543767: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f494c000800 of size 256 next 6\n",
      "2024-06-20 16:02:01.543771: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f494c000900 of size 256 next 4\n",
      "2024-06-20 16:02:01.543775: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f494c000a00 of size 256 next 7\n",
      "2024-06-20 16:02:01.543779: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f494c000b00 of size 367248384 next 8\n",
      "2024-06-20 16:02:01.543784: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4961e3cf00 of size 256 next 9\n",
      "2024-06-20 16:02:01.543788: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4961e3d000 of size 367407104 next 18446744073709551615\n",
      "2024-06-20 16:02:01.543792: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-06-20 16:02:01.543798: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 256 totalling 1.5KiB\n",
      "2024-06-20 16:02:01.543803: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-06-20 16:02:01.543808: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 367248384 totalling 350.24MiB\n",
      "2024-06-20 16:02:01.543812: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 367407104 totalling 350.39MiB\n",
      "2024-06-20 16:02:01.543817: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 700.62MiB\n",
      "2024-06-20 16:02:01.543822: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 734658560 memory_limit_: 734658560 available bytes: 0 curr_region_allocation_bytes_: 1469317120\n",
      "2024-06-20 16:02:01.543834: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       734658560\n",
      "InUse:                       734658304\n",
      "MaxInUse:                    734658560\n",
      "NumAllocs:                          17\n",
      "MaxAllocSize:                367407616\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-06-20 16:02:01.543840: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] ****************************************************************************************************\n",
      "2024-06-20 16:02:01.543883: W tensorflow/core/framework/op_kernel.cc:1827] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m modelcheckpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      9\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mMODEL_WEIGHTS, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m hparams_nrms\u001b[38;5;241m.\u001b[39mhistory_size \u001b[38;5;241m=\u001b[39m HISTORY_SIZE\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNRMSModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams_nrms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mword2vec_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword2vec_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m hist \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     19\u001b[0m     train_dataloader,\n\u001b[1;32m     20\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[1;32m     21\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     22\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[tensorboard_callback, early_stopping, modelcheckpoint],\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_weights(filepath\u001b[38;5;241m=\u001b[39mMODEL_WEIGHTS)\n",
      "File \u001b[0;32m~/Group_33/ebnerd-benchmark/src/ebrec/models/newsrec/nrms.py:42\u001b[0m, in \u001b[0;36mNRMSModel.__init__\u001b[0;34m(self, hparams, word2vec_embedding, word_emb_dim, vocab_size, seed)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2vec_embedding \u001b[38;5;241m=\u001b[39m word2vec_embedding\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# BUILD AND COMPILE MODEL:\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m data_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_loss(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mloss)\n\u001b[1;32m     44\u001b[0m train_optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_opt(\n\u001b[1;32m     45\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39moptimizer, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[1;32m     46\u001b[0m )\n",
      "File \u001b[0;32m~/Group_33/ebnerd-benchmark/src/ebrec/models/newsrec/nrms.py:82\u001b[0m, in \u001b[0;36mNRMSModel._build_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_graph\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build NRMS model and scorer.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m        object: a model used to train.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m        object: a model used to evaluate and inference.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     model, scorer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_nrms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, scorer\n",
      "File \u001b[0;32m~/Group_33/ebnerd-benchmark/src/ebrec/models/newsrec/nrms.py:167\u001b[0m, in \u001b[0;36mNRMSModel._build_nrms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m pred_input_title_one \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(\n\u001b[1;32m    158\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    163\u001b[0m )\n\u001b[1;32m    164\u001b[0m pred_title_one_reshape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mReshape((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mtitle_size,))(\n\u001b[1;32m    165\u001b[0m     pred_input_title_one\n\u001b[1;32m    166\u001b[0m )\n\u001b[0;32m--> 167\u001b[0m titleencoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_newsencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muserencoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_userencoder(titleencoder)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewsencoder \u001b[38;5;241m=\u001b[39m titleencoder\n",
      "File \u001b[0;32m~/Group_33/ebnerd-benchmark/src/ebrec/models/newsrec/nrms.py:127\u001b[0m, in \u001b[0;36mNRMSModel._build_newsencoder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m embedding_layer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mEmbedding(\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2vec_embedding\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2vec_embedding\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    121\u001b[0m     weights\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2vec_embedding],\n\u001b[1;32m    122\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    124\u001b[0m sequences_input_title \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(\n\u001b[1;32m    125\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mtitle_size,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m )\n\u001b[0;32m--> 127\u001b[0m embedded_sequences_title \u001b[38;5;241m=\u001b[39m \u001b[43membedding_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences_input_title\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mdropout)(embedded_sequences_title)\n\u001b[1;32m    130\u001b[0m y \u001b[38;5;241m=\u001b[39m SelfAttention(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mhead_num, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mhead_dim, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)(\n\u001b[1;32m    131\u001b[0m     [y, y, y]\n\u001b[1;32m    132\u001b[0m )\n",
      "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/keras/src/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = PATH.joinpath(\"data/{MODEL_NAME}\")\n",
    "MODEL_WEIGHTS = PATH.joinpath(\"data/state_dict/{MODEL_NAME}/weights\")\n",
    "\n",
    "# CALLBACKS\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=1,\n",
    "    callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    ")\n",
    "_ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_validation = model.scorer.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "    add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    ")\n",
    "df_validation.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "\n",
    "metrics = MetricEvaluator(\n",
    "    labels=df_validation[\"labels\"].to_list(),\n",
    "    predictions=df_validation[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.scorer.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
