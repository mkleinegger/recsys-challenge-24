{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMRS: Hyperparameter Optimization for the NMRS Model\n",
    "\n",
    "This notebook focuses on optimizing the hyperparameters for the NMRS model to achieve the better performance. For this approach we are using a search grid containing following search space:\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'history_size': [10, 50, 100],\n",
    "    'n_users':  [20000, 50000, 70000],\n",
    "    'title_size': [10, 50, 100],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'dropout':  [0.1, 0.3, 0.5]\n",
    "}\n",
    "```\n",
    "\n",
    "The NRMS model is a state-of-the-art neural news recommendation approach with multi-head self-attention. NRMS learns news representations from news titles, using a multi head self-attention network. Briefly speaking, the news encoder first maps each word in the news title to the corresponding vector, and then uses the self-attention network to learn word-level representations. Finally, a query vector is used to locate the important words in the news title, and an attention-based pooling method is used to aggregate the word-level representations into the learned title representations. To learn user representations from their browsed news, NRMS again uses the multi-head self-attention network on top of the learned news representations. The probability of a user clicking a candidate news is given by the dot product between the user representations and the news representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:58:44.274226Z",
     "start_time": "2024-05-18T16:58:39.936186Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 17:26:18.700438: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-08 17:26:18.794582: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 17:26:18.794692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 17:26:18.798042: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-08 17:26:18.817805: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 17:26:23.371445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Import Constants and Utilities\n",
    "from ebrec.utils._constants import (\n",
    "   DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "   DEFAULT_CLICKED_ARTICLES_COL,\n",
    "   DEFAULT_INVIEW_ARTICLES_COL,\n",
    "   DEFAULT_IMPRESSION_ID_COL,\n",
    "   DEFAULT_SUBTITLE_COL,\n",
    "   DEFAULT_LABELS_COL,\n",
    "   DEFAULT_TITLE_COL,\n",
    "   DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "#Import Utility Functions\n",
    "#\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore  \n",
    "from ebrec.models.newsrec.model_config import hparams_lstur\n",
    "\n",
    "#Import NRMS Components\n",
    "#\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Behavior and History Parquet Files\n",
    "The functions below are necessary for transforming the Ebnerd Dataset tables (`history.parquet` and `behaviors.parquet`) into a format suitable for training and testing. This transformation is achieved by joining the histories and behaviors based on the `user ID`. Additionally, preprocessing steps are performed, such as truncating the user history to keep only the specified `history_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Path and Data Configuration\n",
    "Here we setup the `PATH` to the ebenrd dataset we are using for training. `COLUMNS` define the columns we are using for the model training, `TEXT_COLUMNS_TO_USE` contains columns should be considered in the embedding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"NRMS\"\n",
    "\n",
    "DATA_PATH = Path(\"~/shared/194.035-2024S/groups/Gruppe_33/Group_33/data\")\n",
    "DATASPLIT = \"demo\"\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "\n",
    "HISTORY_SIZE = 50\n",
    "MAX_TITLE_LENGTH = 50\n",
    "\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "FRACTION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (\n",
    "    ebnerd_from_path(DATA_PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "df_validation = (\n",
    "    ebnerd_from_path(DATA_PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Articles\n",
    "In this cell we are loading the articles into memory which will later be used for the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pl.read_parquet(DATA_PATH.joinpath(DATASPLIT, \"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and Configure Transformer Model\n",
    "\n",
    "This cell loads a pre-trained transformer model and tokenizer from Hugging Face, specifically FacebookAI/xlm-roberta-base, establishing the NLP backbone for the notebook. The transformer model is critical for transforming raw text data into structured embeddings that can be effectively utilized within the recommendation system. The following steps are executed:\n",
    "- **Load Transformer Model and Tokenizer**: The AutoModel and AutoTokenizer from Hugging Face are used to load the pre-trained xlm-roberta-base model.\n",
    "- **Initialize Word Embeddings**: Word embeddings are initialized using the transformer's word embeddings to enhance the text representation.\n",
    "- **Concatenate Text Columns**: Text columns from the articles dataframe are concatenated to create a comprehensive text field.\n",
    "- **Convert Text to Encodings**: The concatenated text is tokenized and converted to numerical encodings using the transformer tokenizer, with a specified maximum length.\n",
    "- **Create Article Mapping**: A mapping from article IDs to their corresponding tokenized values is created, facilitating efficient lookup and processing in the recommendation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading for Model Input and Model Configuration\n",
    "This cell creates data loaders for both training and validation. The `LSTURDataLoader` is initialized for both training and validation datasets, handling batching, shuffling, and input feature construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look into NRMS hyperparamter attributes\n",
    "This cell is necessery to check which hyperparamter were are interested in optimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute             Value\n",
      "--------------------  ------------------\n",
      "attention_hidden_dim  200\n",
      "dropout               0.2\n",
      "head_dim              20\n",
      "head_num              20\n",
      "history_size          50\n",
      "learning_rate         0.0001\n",
      "loss                  cross_entropy_loss\n",
      "optimizer             adam\n",
      "title_size            30\n"
     ]
    }
   ],
   "source": [
    "# Get attributes of hparams_lstur\n",
    "attributes = dir(hparams_nrms)\n",
    "\n",
    "# Prepare data for tabulate\n",
    "data = [(attr, getattr(hparams_nrms, attr)) for attr in attributes if not attr.startswith('__')]\n",
    "\n",
    "# Print as a table\n",
    "print(tabulate(data, headers=[\"Attribute\", \"Value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization for NRMS Model\n",
    "In this section, we perform hyperparameter optimization to find the best combination of parameters for the LSTUR model. The optimization focuses on input dimensions such as `history_size`, `n_users`, and `title_size`, as well as model-specific parameters like `learning_rate` and `dropout`. The process involves evaluating different combinations of these parameters to identify the configuration that yields the best performance.\n",
    "\n",
    "### Setting Up Hyperparameter Optimization\n",
    "The `objective` function is defined to train the LSTUR model with a given set of hyperparameters and evaluate its performance. The function creates directories for logs and model weights, sets the hyperparameters, trains the model, and then evaluates it. The evaluation results are saved, and predictions are written to a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Hyperopt\n",
    "def objective(learning_rate, dropout, df_validation,df_train):\n",
    "\n",
    "    # Create directories for logs and model weights\n",
    "    MODEL_NAME = f\"NRMS_l{learning_rate}_d{dropout}\"\n",
    "    LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "    MODEL_WEIGHTS = f\"downloads/data/state_dict/{MODEL_NAME}/weights\"\n",
    "    RESULTS_DIR = f\"downloads/evaluations/{MODEL_NAME}\"\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "    modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    # Set the parameters\n",
    "    hparams_nrms.history_size = HISTORY_SIZE\n",
    "    hparams_nrms.title_size = MAX_TITLE_LENGTH\n",
    "    hparams_nrms.learning_rate = learning_rate\n",
    "    hparams_nrms.dropout = dropout\n",
    "    \n",
    "\n",
    "    model = NRMSModel(\n",
    "        hparams=hparams_lstur,\n",
    "        word2vec_embedding=word2vec_embedding,\n",
    "        seed=42,\n",
    "    )\n",
    "    hist = model.model.fit(\n",
    "        train_dataloader,\n",
    "        validation_data=val_dataloader,\n",
    "        epochs=1,\n",
    "        callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    "    )\n",
    "    _ = model.model.load_weights(filepath=MODEL_WEIGHTS)\n",
    "\n",
    "\n",
    "    \n",
    "    pred_validation = model.scorer.predict(val_dataloader)\n",
    "    df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "        add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    "    )\n",
    "\n",
    "    metrics = MetricEvaluator(\n",
    "        labels=df_validation[\"labels\"].to_list(),\n",
    "        predictions=df_validation[\"scores\"].to_list(),\n",
    "        metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    "    )\n",
    "    evaluation_results = metrics.evaluate().evaluations\n",
    "\n",
    "    # Save the evaluation results\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    with open(os.path.join(RESULTS_DIR, 'evaluation_results.txt'), 'w') as f:\n",
    "        for key, value in evaluation_results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "    # Rank predictions and write submission file\n",
    "    df_validation = df_validation.with_columns(\n",
    "        pl.col(\"scores\")\n",
    "        .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "        .alias(\"ranked_scores\")\n",
    "    )\n",
    "    write_submission_file(\n",
    "        impression_ids=df_validation[DEFAULT_IMPRESSION_ID_COL],\n",
    "        prediction_scores=df_validation[\"ranked_scores\"],\n",
    "        path=os.path.join(RESULTS_DIR, \"predictions.txt\"),\n",
    "    )\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "param_grid = {\n",
    "    'history_size': [10, 50, 100],\n",
    "    'n_users':  [20000, 50000, 70000],\n",
    "    'title_size': [10, 50, 100],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'dropout':  [0.2],\n",
    "    'batch_size': 64,\n",
    "}\n",
    "\n",
    "combinations = list(\n",
    "    itertools.product(\n",
    "        # param_grid['history_size'], param_grid['n_users'], param_grid['title_size'], \n",
    "        param_grid['learning_rate'], param_grid['dropout']\n",
    "    )\n",
    ")\n",
    "\n",
    "all_results = []\n",
    "for learning_rate, dropout in combinations:\n",
    "    print(f\"Evaluating combination: history_size={history_size}, n_users={n_users}, title_size={title_size}\")\n",
    "    result = objective(learning_rate, dropout, df_validation, df_train)\n",
    "    all_results.append({\n",
    "        'learning_rate': learning_rate,\n",
    "        'dropout': dropout,\n",
    "        'evaluation_results': result\n",
    "    })\n",
    "\n",
    "# Save all results to a file\n",
    "with open(\"downloads/evaluations/all_results.txt\", 'w') as f:\n",
    "    for result in all_results:\n",
    "        f.write(f\"{result}\\n\")\n",
    "\n",
    "print(\"All combinations evaluated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g33",
   "language": "python",
   "name": "g33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
