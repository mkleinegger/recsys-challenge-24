{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up ebrec Environment: Cloning, Installing Dependencies, and Libraries\n",
    "### Here we will be  managing dependencies using Poetry and installing necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ebnerd-benchmark' already exists and is not an empty directory.\n",
      "Collecting polars\n",
      "  Using cached polars-0.20.31-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Using cached polars-0.20.31-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.8 MB)\n",
      "Installing collected packages: polars\n",
      "Successfully installed polars-0.20.31\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.39.1)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: polars in /opt/conda/lib/python3.11/site-packages (0.20.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "#Cloning our ebrec\n",
    "!git clone https://github.com/ebanalyse/ebnerd-benchmark.git\n",
    "\n",
    "#Poetry\n",
    "#!curl -sSL https://install.python-poetry.org | python3\n",
    "#!python3 -m poetry shell\n",
    "#!python3 -m poetry add ebrec\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Pip\n",
    "#!pip install ebrec\n",
    "!pip install polars\n",
    "!pip install transformers tensorflow polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:58:47.920171Z",
     "start_time": "2024-05-18T16:58:47.839314Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/e12242664/Group_33/notebooks/ebnerd-benchmark\n",
      "Processing /home/e12242664/Group_33/notebooks/ebnerd-benchmark\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<4.37.3,>=4.30.0 (from ebrec==0.0.1)\n",
      "  Using cached transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "Requirement already satisfied: tensorflow<2.16.0,>=2.12.0 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (2.15.0)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (2.1.2+cu121)\n",
      "Collecting scikit-learn==1.4.0 (from ebrec==0.0.1)\n",
      "  Using cached scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy<1.26.1,>=1.24.0 (from ebrec==0.0.1)\n",
      "  Using cached numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting polars==0.20.8 (from ebrec==0.0.1)\n",
      "  Using cached polars-0.20.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from ebrec==0.0.1) (4.66.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0->ebrec==0.0.1) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0->ebrec==0.0.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0->ebrec==0.0.1) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (4.10.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (3.13.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->ebrec==0.0.1) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (0.22.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (0.4.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->ebrec==0.0.1) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<2.3.0,>=2.0.0->ebrec==0.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch<2.3.0,>=2.0.0->ebrec==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->ebrec==0.0.1) (3.2.2)\n",
      "Using cached polars-0.20.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.8 MB)\n",
      "Using cached scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Using cached numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "Building wheels for collected packages: ebrec\n",
      "  Building wheel for ebrec (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ebrec: filename=ebrec-0.0.1-py3-none-any.whl size=74959 sha256=271eaac42898186245650eb2b9e5af15481180f441e831403b7fbbc9d86c3bdd\n",
      "  Stored in directory: /home/e12242664/.cache/pip/wheels/84/cb/a5/8f021c4487dee3a9d67f31720d068a121bbe9e01e593380b76\n",
      "Successfully built ebrec\n",
      "Installing collected packages: polars, numpy, scikit-learn, transformers, ebrec\n",
      "  Attempting uninstall: polars\n",
      "    Found existing installation: polars 0.20.31\n",
      "    Uninstalling polars-0.20.31:\n",
      "      Successfully uninstalled polars-0.20.31\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.4.1.post1\n",
      "    Uninstalling scikit-learn-1.4.1.post1:\n",
      "      Successfully uninstalled scikit-learn-1.4.1.post1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.39.1\n",
      "    Uninstalling transformers-4.39.1:\n",
      "      Successfully uninstalled transformers-4.39.1\n",
      "Successfully installed ebrec-0.0.1 numpy-1.26.0 polars-0.20.8 scikit-learn-1.4.0 transformers-4.37.2\n"
     ]
    }
   ],
   "source": [
    "%cd ebnerd-benchmark\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Data Processing and Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:58:44.274226Z",
     "start_time": "2024-05-18T16:58:39.936186Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 07:37:32.018543: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-21 07:37:32.018623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-21 07:37:32.022539: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-21 07:37:32.041635: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 07:37:33.678363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "   DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "   DEFAULT_CLICKED_ARTICLES_COL,\n",
    "   DEFAULT_INVIEW_ARTICLES_COL,\n",
    "   DEFAULT_IMPRESSION_ID_COL,\n",
    "   DEFAULT_SUBTITLE_COL,\n",
    "   DEFAULT_LABELS_COL,\n",
    "   DEFAULT_TITLE_COL,\n",
    "   DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "\n",
    "#\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "\n",
    "#\n",
    "from ebrec.models.newsrec.dataloader import LSTURDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import LSTURModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Ebnerd Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing for Training, Validation, and Testing\n",
    "### This code snippet loads and preprocesses data from the Ebnerd dataset for three purposes: training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>1148586</td><td>[9769994, 9769478, … 9769765]</td><td>[9774542, 9774542, … 9774554]</td><td>[9774554]</td><td>308255978</td><td>[0, 0, … 1]</td></tr><tr><td>850523</td><td>[9738263, 9738105, … 9755181]</td><td>[9759955, 9778661, … 9778444]</td><td>[9759955]</td><td>237203945</td><td>[1, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 1148586 ┆ [9769994,         ┆ [9774542,         ┆ [9774554]        ┆ 308255978     ┆ [0, 0, … 1] │\n",
       "│         ┆ 9769478, …        ┆ 9774542, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9769765]          ┆ 9774554]          ┆                  ┆               ┆             │\n",
       "│ 850523  ┆ [9738263,         ┆ [9759955,         ┆ [9759955]        ┆ 237203945     ┆ [1, 0, … 0] │\n",
       "│         ┆ 9738105, …        ┆ 9778661, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9755181]          ┆ 9778444]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path(\"/home/e12242664/shared/194.035-2024S/groups/Gruppe_33/Group_33/downloads\")\n",
    "DATASPLIT = \"demo\"\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 10\n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "df_test = (ebnerd_from_path(PATH.joinpath(\"test\"), history_size=HISTORY_SIZE)\n",
    "    .select([\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "        \n",
    "])\n",
    "            .sample(fraction=FRACTION)\n",
    "          )\n",
    "    \n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the difference between Training/Validation and Testset\n",
    "### Note, the testset doesn't include labels, and we have remove some of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train:\n",
      "shape: (2, 6)\n",
      "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
      "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
      "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
      "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
      "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
      "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
      "│ 1148586 ┆ [9769994,         ┆ [9774542,         ┆ [9774554]        ┆ 308255978     ┆ [0, 0, … 1] │\n",
      "│         ┆ 9769478, …        ┆ 9774542, …        ┆                  ┆               ┆             │\n",
      "│         ┆ 9769765]          ┆ 9774554]          ┆                  ┆               ┆             │\n",
      "│ 850523  ┆ [9738263,         ┆ [9759955,         ┆ [9759955]        ┆ 237203945     ┆ [1, 0, … 0] │\n",
      "│         ┆ 9738105, …        ┆ 9778661, …        ┆                  ┆               ┆             │\n",
      "│         ┆ 9755181]          ┆ 9778444]          ┆                  ┆               ┆             │\n",
      "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘\n",
      "\n",
      "df_validation:\n",
      "shape: (2, 6)\n",
      "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
      "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
      "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
      "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
      "│         ┆                   ┆ list[i32]         ┆ list[i32]        ┆               ┆             │\n",
      "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
      "│ 2052088 ┆ [9778952,         ┆ [9789600,         ┆ [9789664]        ┆ 100989065     ┆ [0, 0, … 1] │\n",
      "│         ┆ 9777636, …        ┆ 9789866, …        ┆                  ┆               ┆             │\n",
      "│         ┆ 9779577]          ┆ 9789664]          ┆                  ┆               ┆             │\n",
      "│ 251987  ┆ [9775793,         ┆ [9773779,         ┆ [9789502]        ┆ 558632238     ┆ [0, 0, … 0] │\n",
      "│         ┆ 9775489, …        ┆ 9783655, …        ┆                  ┆               ┆             │\n",
      "│         ┆ 9769917]          ┆ 9787332]          ┆                  ┆               ┆             │\n",
      "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘\n",
      "\n",
      "df_test:\n",
      "shape: (2, 4)\n",
      "┌─────────┬───────────────────────────────┬───────────────────────────────┬───────────────┐\n",
      "│ user_id ┆ article_id_fixed              ┆ article_ids_inview            ┆ impression_id │\n",
      "│ ---     ┆ ---                           ┆ ---                           ┆ ---           │\n",
      "│ u32     ┆ list[i32]                     ┆ list[i32]                     ┆ u32           │\n",
      "╞═════════╪═══════════════════════════════╪═══════════════════════════════╪═══════════════╡\n",
      "│ 2060501 ┆ [9790052, 9790476, … 9756075] ┆ [9798724, 9798889, … 9486080] ┆ 321876000     │\n",
      "│ 2192684 ┆ [9789911, 9790682, … 9790859] ┆ [9378062, 9797882, … 9460933] ┆ 160675284     │\n",
      "└─────────┴───────────────────────────────┴───────────────────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"df_train:\")\n",
    "print(df_train.head(2))\n",
    "\n",
    "print(\"\\ndf_validation:\")\n",
    "print(df_validation.head(2))\n",
    "\n",
    "print(\"\\ndf_test:\")\n",
    "print(df_test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the First 5 Rows of df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3037230</td><td>&quot;Ishockey-spill…</td><td>&quot;ISHOCKEY: Isho…</td><td>2023-06-29 06:20:57</td><td>false</td><td>&quot;Ambitionerne o…</td><td>2003-08-28 08:55:00</td><td>null</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Mindre ulykke&quot;]</td><td>142</td><td>[327, 334]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr><tr><td>3044020</td><td>&quot;Prins Harry tv…</td><td>&quot;Hoffet tvang P…</td><td>2023-06-29 06:21:16</td><td>false</td><td>&quot;Den britiske t…</td><td>2005-06-29 08:47:00</td><td>[3097307, 3097197, 3104927]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Harry&quot;, &quot;James Hewitt&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Personfarlig kriminalitet&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7084</td><td>&quot;Negative&quot;</td></tr><tr><td>3057622</td><td>&quot;Rådden kørsel …</td><td>&quot;Kan ikke straf…</td><td>2023-06-29 06:21:24</td><td>false</td><td>&quot;Slingrende spr…</td><td>2005-10-10 07:20:00</td><td>[3047102]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Transportmiddel&quot;, &quot;Bil&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9236</td><td>&quot;Negative&quot;</td></tr><tr><td>3073151</td><td>&quot;Mærsk-arvinger…</td><td>&quot;FANGET I FLODB…</td><td>2023-06-29 06:21:38</td><td>false</td><td>&quot;To oldebørn af…</td><td>2005-01-04 06:59:00</td><td>[3067474, 3067478, 3153705]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Privat virksomhed&quot;, … &quot;Rejse&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9945</td><td>&quot;Negative&quot;</td></tr><tr><td>3193383</td><td>&quot;Skød svigersøn…</td><td>&quot;44-årig kvinde…</td><td>2023-06-29 06:22:57</td><td>false</td><td>&quot;En 44-årig mor…</td><td>2003-09-15 15:30:00</td><td>null</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9966</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3037230   ┆ Ishockey- ┆ ISHOCKEY: ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ spiller:  ┆ Ishockey- ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Jeg       ┆ spilleren ┆ 06:20:57  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ troede    ┆ Seb…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ jeg…      ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3044020   ┆ Prins     ┆ Hoffet    ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7084    ┆ Negative │\n",
       "│           ┆ Harry     ┆ tvang     ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tvunget   ┆ Prins     ┆ 06:21:16  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ til       ┆ Harry til ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dna-test  ┆ at …      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3057622   ┆ Rådden    ┆ Kan ikke  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9236    ┆ Negative │\n",
       "│           ┆ kørsel på ┆ straffes: ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ blå       ┆ Udenlands ┆ 06:21:24  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ plader    ┆ ke d…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3073151   ┆ Mærsk-arv ┆ FANGET I  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9945    ┆ Negative │\n",
       "│           ┆ inger i   ┆ FLODBØLGE ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ livsfare  ┆ N: Skibsr ┆ 06:21:38  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ edere…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3193383   ┆ Skød      ┆ 44-årig   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9966    ┆ Negative │\n",
       "│           ┆ svigersøn ┆ kvinde    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gennem    ┆ tiltalt   ┆ 06:22:57  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ babydyne  ┆ for drab  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ …         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_articles = pl.read_parquet(PATH.joinpath(DATASPLIT, \"articles.parquet\"))\n",
    "df_articles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Text Data with XLM-RoBERTa for Article Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 50\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating LSTUR DataLoaders for Training and Validation\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_mapping = {user_id: i for i, user_id in enumerate(df_train[DEFAULT_USER_COL].unique())}\n",
    "\n",
    "train_dataloader = LSTURDataLoader(\n",
    "    user_id_mapping=user_id_mapping,\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n",
    "val_dataloader = LSTURDataLoader(\n",
    "    user_id_mapping=user_id_mapping,\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute             Value\n",
      "--------------------  ------------------\n",
      "attention_hidden_dim  200\n",
      "cnn_activation        relu\n",
      "dropout               0.2\n",
      "filter_num            400\n",
      "gru_unit              400\n",
      "history_size          50\n",
      "learning_rate         0.0001\n",
      "loss                  cross_entropy_loss\n",
      "n_users               50000\n",
      "optimizer             adam\n",
      "title_size            30\n",
      "type                  ini\n",
      "window_size           3\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from ebrec.models.newsrec.model_config import hparams_lstur\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Get attributes of hparams_lstur\n",
    "attributes = dir(hparams_lstur)\n",
    "\n",
    "# Prepare data for tabulate\n",
    "data = [(attr, getattr(hparams_lstur, attr)) for attr in attributes if not attr.startswith('__')]\n",
    "\n",
    "# Print as a table\n",
    "print(tabulate(data, headers=[\"Attribute\", \"Value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization for LSTUR Model Training\n",
    "#### This script performs hyperparameter optimization for training an LSTUR model using TensorFlow. It evaluates different combinations of history_size, n_users, title_size, learning_rate, and dropout to find the optimal settings that maximize evaluation metrics like AUC, MRR, and NDCG at k=5 and k=10 on a validation dataset. Results are saved for each combination in downloads/evaluations/all_results.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating combination: history_size=25, n_users=50000, title_size=27\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 400), dtype=tf.float32, name=None), name='att_layer2_2/Sum_1:0', description=\"created by layer 'att_layer2_2'\")\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 07:55:59.549311: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 46080368640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00000, saving model to downloads/data/state_dict/LSTUR_l0.0001_d0.2/weights\n",
      "4/4 [==============================] - 49s 12s/step - loss: 1.5991 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node model_5/reshape_4/Reshape defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/opt/conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_270/677300949.py\", line 92, in <module>\n\n  File \"/tmp/ipykernel_270/677300949.py\", line 40, in objective\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/layers/reshaping/reshape.py\", line 137, in call\n\nInput to reshape is a tensor with 2800 values, but the requested shape has 1512\n\t [[{{node model_5/reshape_4/Reshape}}]] [Op:__inference_predict_function_52363]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 92\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m history_size, n_users, title_size, learning_rate, dropout \u001b[38;5;129;01min\u001b[39;00m combinations:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating combination: history_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_users=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_users\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, title_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory_size\u001b[39m\u001b[38;5;124m'\u001b[39m: history_size,\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_users\u001b[39m\u001b[38;5;124m'\u001b[39m: n_users,\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle_size\u001b[39m\u001b[38;5;124m'\u001b[39m: title_size,\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation_results\u001b[39m\u001b[38;5;124m'\u001b[39m: result\n\u001b[1;32m     98\u001b[0m     })\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Save all results to a file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 40\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(history_size, n_users, title_size, learning_rate, dropout, df_validation, df_train)\u001b[0m\n\u001b[1;32m     30\u001b[0m hist \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     31\u001b[0m     train_dataloader,\n\u001b[1;32m     32\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[1;32m     33\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     34\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[tensorboard_callback, early_stopping, modelcheckpoint],\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_weights(filepath\u001b[38;5;241m=\u001b[39mMODEL_WEIGHTS)\n\u001b[0;32m---> 40\u001b[0m pred_validation \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m df_validation \u001b[38;5;241m=\u001b[39m add_prediction_scores(df_validation, pred_validation\u001b[38;5;241m.\u001b[39mtolist())\u001b[38;5;241m.\u001b[39mpipe(\n\u001b[1;32m     42\u001b[0m     add_known_user_column, known_users\u001b[38;5;241m=\u001b[39mdf_train[DEFAULT_USER_COL]\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mebrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node model_5/reshape_4/Reshape defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/opt/conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_270/677300949.py\", line 92, in <module>\n\n  File \"/tmp/ipykernel_270/677300949.py\", line 40, in objective\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/layers/reshaping/reshape.py\", line 137, in call\n\nInput to reshape is a tensor with 2800 values, but the requested shape has 1512\n\t [[{{node model_5/reshape_4/Reshape}}]] [Op:__inference_predict_function_52363]"
     ]
    }
   ],
   "source": [
    "# Performing Hyperopt\n",
    "\n",
    "def objective(history_size, n_users, title_size, learning_rate, dropout, df_validation,df_train):\n",
    "\n",
    "    # Create directories for logs and model weights\n",
    "    MODEL_NAME = f\"LSTUR_l{learning_rate}_d{dropout}\"\n",
    "    LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "    MODEL_WEIGHTS = f\"downloads/data/state_dict/{MODEL_NAME}/weights\"\n",
    "    RESULTS_DIR = f\"downloads/evaluations/{MODEL_NAME}\"\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "    modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    # Set the parameters\n",
    "    hparams_lstur.history_size = history_size\n",
    "    hparams_lstur.n_users = n_users\n",
    "    hparams_lstur.title_size = title_size\n",
    "    hparams_lstur.learning_rate = learning_rate\n",
    "    hparams_lstur.dropout = dropout\n",
    "    \n",
    "\n",
    "    model = LSTURModel(\n",
    "        hparams=hparams_lstur,\n",
    "        word2vec_embedding=word2vec_embedding,\n",
    "        seed=42,\n",
    "    )\n",
    "    hist = model.model.fit(\n",
    "        train_dataloader,\n",
    "        validation_data=val_dataloader,\n",
    "        epochs=1,\n",
    "        callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    "    )\n",
    "    _ = model.model.load_weights(filepath=MODEL_WEIGHTS)\n",
    "\n",
    "\n",
    "    \n",
    "    pred_validation = model.scorer.predict(val_dataloader)\n",
    "    df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "        add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    "    )\n",
    "\n",
    "    from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "    \n",
    "    metrics = MetricEvaluator(\n",
    "        labels=df_validation[\"labels\"].to_list(),\n",
    "        predictions=df_validation[\"scores\"].to_list(),\n",
    "        metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    "    )\n",
    "    evaluation_results = metrics.evaluate().evaluations\n",
    "\n",
    "    # Save the evaluation results\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    with open(os.path.join(RESULTS_DIR, 'evaluation_results.txt'), 'w') as f:\n",
    "        for key, value in evaluation_results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "    # Rank predictions and write submission file\n",
    "    df_validation = df_validation.with_columns(\n",
    "        pl.col(\"scores\")\n",
    "        .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "        .alias(\"ranked_scores\")\n",
    "    )\n",
    "    write_submission_file(\n",
    "        impression_ids=df_validation[DEFAULT_IMPRESSION_ID_COL],\n",
    "        prediction_scores=df_validation[\"ranked_scores\"],\n",
    "        path=os.path.join(RESULTS_DIR, \"predictions.txt\"),\n",
    "    )\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "param_grid = {\n",
    "    'history_size': [25],\n",
    "    'n_users':  [50000],\n",
    "    'title_size': [27],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'dropout':  [0.2],\n",
    "    'batch_size': 64,\n",
    "}\n",
    "\n",
    "combinations = list(\n",
    "    itertools.product(\n",
    "        param_grid['history_size'], param_grid['n_users'], param_grid['title_size'], param_grid['learning_rate'], param_grid['dropout']\n",
    "    )\n",
    ")\n",
    "\n",
    "all_results = []\n",
    "for history_size, n_users, title_size, learning_rate, dropout in combinations:\n",
    "    print(f\"Evaluating combination: history_size={history_size}, n_users={n_users}, title_size={title_size}\")\n",
    "    result = objective(history_size, n_users, title_size, learning_rate, dropout, df_validation, df_train)\n",
    "    all_results.append({\n",
    "        'history_size': history_size,\n",
    "        'n_users': n_users,\n",
    "        'title_size': title_size,\n",
    "        'evaluation_results': result\n",
    "    })\n",
    "\n",
    "# Save all results to a file\n",
    "with open(\"downloads/evaluations/all_results.txt\", 'w') as f:\n",
    "    for result in all_results:\n",
    "        f.write(f\"{result}\\n\")\n",
    "        \n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"All combinations evaluated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
