{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c7f689",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Recommenders contributors.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1778d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/e11908553/Group_33\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dacy<3.0.0,>=2.7.7 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (2.7.7)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.2 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (4.3.2)\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: numpy<1.26.1,>=1.24.0 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (1.26.0)\n",
      "Requirement already satisfied: polars==0.20.8 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (0.20.8)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (6.0.1)\n",
      "Requirement already satisfied: recommenders<1.3,>=1.2 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn==1.4.0 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (1.4.0)\n",
      "Requirement already satisfied: scipy==1.12 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (1.12.0)\n",
      "Requirement already satisfied: tensorflow<2.16.0,>=2.12 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (2.15.0.post1)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (2.2.0+cpu)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from group-33==0.1.0) (4.66.1)\n",
      "Requirement already satisfied: transformers<4.37.3,>=4.30.0 in /opt/conda/lib/python3.11/site-packages (from transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (4.36.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0->group-33==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0->group-33==0.1.0) (3.2.0)\n",
      "Requirement already satisfied: spacy-wrap>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from dacy<3.0.0,>=2.7.7->group-33==0.1.0) (1.4.5)\n",
      "Requirement already satisfied: spacy-experimental>=0.6.2 in /opt/conda/lib/python3.11/site-packages (from dacy<3.0.0,>=2.7.7->group-33==0.1.0) (0.6.4)\n",
      "Requirement already satisfied: spacy>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (3.7.4)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from dacy<3.0.0,>=2.7.7->group-33==0.1.0) (2.2.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.11/site-packages (from gensim<5.0.0,>=4.3.2->group-33==0.1.0) (6.4.0)\n",
      "Requirement already satisfied: category-encoders<3,>=2.6.0 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (2.6.3)\n",
      "Requirement already satisfied: cornac<2,>=1.15.2 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (1.18.0)\n",
      "Requirement already satisfied: hyperopt<1,>=0.2.7 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (0.2.7)\n",
      "Requirement already satisfied: lightfm<2,>=1.17 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (1.17)\n",
      "Requirement already satisfied: lightgbm<5,>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (4.3.0)\n",
      "Requirement already satisfied: locust<3,>=2.12.2 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (2.29.1)\n",
      "Requirement already satisfied: memory-profiler<1,>=0.61.0 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (0.61.0)\n",
      "Requirement already satisfied: nltk<4,>=3.8.1 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (3.8.1)\n",
      "Requirement already satisfied: notebook<8,>=7.0.0 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (7.0.6)\n",
      "Requirement already satisfied: numba<1,>=0.57.0 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (0.58.1)\n",
      "Requirement already satisfied: retrying<2,>=1.3.4 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (1.3.4)\n",
      "Requirement already satisfied: scikit-surprise>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (1.1.4)\n",
      "Requirement already satisfied: seaborn<1,>=0.13.0 in /opt/conda/lib/python3.11/site-packages (from recommenders<1.3,>=1.2->group-33==0.1.0) (0.13.0)\n",
      "Requirement already satisfied: pandera>=0.15.0 in /opt/conda/lib/python3.11/site-packages (from pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (0.20.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (2.15.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.2.5.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (12.2.5.6)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.2.142 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (12.2.142)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.2.140 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (12.2.140)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.2.140 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (12.2.140)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.2.140 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (12.2.140)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.4.25 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (8.9.4.25)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.8.103 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (11.0.8.103)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.3.141 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (10.3.3.141)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.5.2.141 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (11.5.2.141)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.2.141 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (12.1.2.141)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.16.5 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (2.16.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.2.140 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (12.2.140)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->group-33==0.1.0) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->group-33==0.1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->group-33==0.1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->group-33==0.1.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<2.3.0,>=2.0.0->group-33==0.1.0) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (0.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (0.4.2)\n",
      "\u001b[33mWARNING: transformers 4.36.2 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: qtconsole in /opt/conda/lib/python3.11/site-packages (from jupyter->group-33==0.1.0) (5.5.1)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.11/site-packages (from jupyter->group-33==0.1.0) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.11/site-packages (from jupyter->group-33==0.1.0) (7.11.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.11/site-packages (from jupyter->group-33==0.1.0) (6.26.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (from jupyter->group-33==0.1.0) (8.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (0.42.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from category-encoders<3,>=2.6.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.14.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.11/site-packages (from category-encoders<3,>=2.6.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.5.3)\n",
      "Requirement already satisfied: powerlaw in /opt/conda/lib/python3.11/site-packages (from cornac<2,>=1.15.2->recommenders<1.3,>=1.2->group-33==0.1.0) (1.5)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.11/site-packages (from hyperopt<1,>=0.2.7->recommenders<1.3,>=1.2->group-33==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from hyperopt<1,>=0.2.7->recommenders<1.3,>=1.2->group-33==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.11/site-packages (from hyperopt<1,>=0.2.7->recommenders<1.3,>=1.2->group-33==0.1.0) (0.10.9.7)\n",
      "Requirement already satisfied: gevent>=22.10.2 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (24.2.1)\n",
      "Requirement already satisfied: flask>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (3.0.1)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (1.0.7)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (25.1.1)\n",
      "Requirement already satisfied: geventhttpclient>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (2.3.1)\n",
      "Requirement already satisfied: ConfigArgParse>=1.5.5 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (1.7)\n",
      "Requirement already satisfied: psutil>=5.9.1 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (5.9.5)\n",
      "Requirement already satisfied: Flask-Login>=0.6.3 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (0.6.3)\n",
      "Requirement already satisfied: Flask-Cors>=3.0.10 in /opt/conda/lib/python3.11/site-packages (from locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (4.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk<4,>=3.8.1->recommenders<1.3,>=1.2->group-33==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.10.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /opt/conda/lib/python3.11/site-packages (from notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.25.2)\n",
      "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /opt/conda/lib/python3.11/site-packages (from notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (4.0.9)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/conda/lib/python3.11/site-packages (from notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (6.3.3)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba<1,>=0.57.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.41.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (2023.3)\n",
      "Requirement already satisfied: multimethod<=1.10.0 in /opt/conda/lib/python3.11/site-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (1.10)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (2.6.1)\n",
      "Requirement already satisfied: typeguard in /opt/conda/lib/python3.11/site-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (2.13.3)\n",
      "Requirement already satisfied: typing-inspect>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: hypothesis>=6.92.7 in /opt/conda/lib/python3.11/site-packages (from pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (6.105.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<4.37.3,>=4.30.0->transformers[and-cuda]<4.37.3,>=4.30.0->group-33==0.1.0) (2023.11.17)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /opt/conda/lib/python3.11/site-packages (from seaborn<1,>=0.13.0->recommenders<1.3,>=1.2->group-33==0.1.0) (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-transformers>=1.2.1 in /opt/conda/lib/python3.11/site-packages (from spacy-wrap>=1.4.1->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (1.3.5)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (2.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (0.7.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter->group-33==0.1.0) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter->group-33==0.1.0) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter->group-33==0.1.0) (8.18.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter->group-33==0.1.0) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter->group-33==0.1.0) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter->group-33==0.1.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter->group-33==0.1.0) (1.5.8)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter->group-33==0.1.0) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter->group-33==0.1.0) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter->group-33==0.1.0) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<2.3.0,>=2.0.0->group-33==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter->group-33==0.1.0) (3.0.41)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter->group-33==0.1.0) (2.17.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (0.7.4)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter->group-33==0.1.0) (1.2.1)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from qtconsole->jupyter->group-33==0.1.0) (2.4.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch<2.3.0,>=2.0.0->group-33==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter->group-33==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.11/site-packages (from flask>=2.0.0->locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.11/site-packages (from flask>=2.0.0->locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: zope.event in /opt/conda/lib/python3.11/site-packages (from gevent>=22.10.2->locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (5.0)\n",
      "Requirement already satisfied: zope.interface in /opt/conda/lib/python3.11/site-packages (from gevent>=22.10.2->locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (6.4.post2)\n",
      "Requirement already satisfied: greenlet>=3.0rc3 in /opt/conda/lib/python3.11/site-packages (from gevent>=22.10.2->locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (3.0.1)\n",
      "Requirement already satisfied: brotli in /opt/conda/lib/python3.11/site-packages (from geventhttpclient>=2.3.1->locust<3,>=2.12.2->recommenders<1.3,>=1.2->group-33==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from hypothesis>=6.92.7->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from hypothesis>=6.92.7->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (0.19.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (4.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->group-33==0.1.0) (4.0.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (4.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.4.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.19.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.18.0)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.6.4)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.13.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (4.20.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn<1,>=0.13.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn<1,>=0.13.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn<1,>=0.13.0->recommenders<1.3,>=1.2->group-33==0.1.0) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn<1,>=0.13.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn<1,>=0.13.0->recommenders<1.3,>=1.2->group-33==0.1.0) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn<1,>=0.13.0->recommenders<1.3,>=1.2->group-33==0.1.0) (3.1.1)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter->group-33==0.1.0) (2.19.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->group-33==0.1.0) (0.2.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /opt/conda/lib/python3.11/site-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (2.16.2)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /opt/conda/lib/python3.11/site-packages (from spacy-transformers>=1.2.1->spacy-wrap>=1.4.1->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (0.9.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (0.1.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect>=0.6.0->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders<1.3,>=1.2->group-33==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy>=3.2.0->spacy[transformers]>=3.2.0->dacy<3.0.0,>=2.7.7->group-33==0.1.0) (0.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter->group-33==0.1.0) (2.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (0.8.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.13.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (0.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12->tensorflow[and-cuda]<2.16.0,>=2.12->group-33==0.1.0) (3.2.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (21.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->group-33==0.1.0) (0.2.2)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.4)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8,>=7.0.0->recommenders<1.3,>=1.2->group-33==0.1.0) (2.8.19.14)\n",
      "Building wheels for collected packages: group-33\n",
      "  Building editable for group-33 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for group-33: filename=group_33-0.1.0-py3-none-any.whl size=3120 sha256=05dc8d833ff2d9413139c0d4d4ee0726cd2fd300ce009621ccc4d5deb77ba27f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-fpk3hn5i/wheels/f2/0a/5b/c2efd7720345def7987521ea9f230bb9a0baba13f094bd881e\n",
      "Successfully built group-33\n",
      "Installing collected packages: group-33\n",
      "  Attempting uninstall: group-33\n",
      "    Found existing installation: group-33 0.1.0\n",
      "    Uninstalling group-33-0.1.0:\n",
      "      Successfully uninstalled group-33-0.1.0\n",
      "Successfully installed group-33-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!cd .. && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b598b21",
   "metadata": {},
   "source": [
    "# DKN : Deep Knowledge-Aware Network for News Recommendation\n",
    "\n",
    "DKN \\[1\\] is a deep learning model which incorporates information from knowledge graph for better news recommendation. Specifically, DKN uses TransX \\[2\\] method for knowledge graph representation learning, then applies a CNN framework, named KCNN, to combine entity embedding with word embedding and generate a final embedding vector for a news article. CTR prediction is made via an attention-based neural scorer.\n",
    "\n",
    "## Properties of DKN:\n",
    "\n",
    "- DKN is a content-based deep model for CTR prediction rather than traditional ID-based collaborative filtering.\n",
    "- It makes use of knowledge entities and common sense in news content via joint learning from semantic-level and knowledge-level representations of news articles.\n",
    "- DKN uses an attention module to dynamically calculate a user's aggregated historical representation.\n",
    "\n",
    "\n",
    "## Data format\n",
    "\n",
    "DKN takes several files as input as follows:\n",
    "\n",
    "- **training / validation / test files**: each line in these files represents one instance. Impressionid is used to evaluate performance within an impression session, so it is only used when evaluating, you can set it to 0 for training data. The format is : <br>\n",
    "`[label] [userid] [CandidateNews]%[impressionid] `<br>\n",
    "e.g., `1 train_U1 N1%0` <br>\n",
    "\n",
    "- **user history file**: each line in this file represents a users' click history. You need to set `history_size` parameter in the config file, which is the max number of user's click history we use. We will automatically keep the last `history_size` number of user click history, if user's click history is more than `history_size`, and we will automatically pad with 0 if user's click history is less than `history_size`. the format is : <br>\n",
    "`[Userid] [newsid1,newsid2...]`<br>\n",
    "e.g., `train_U1 N1,N2` <br>\n",
    "\n",
    "- **document feature file**: It contains the word and entity features for news articles. News articles are represented by aligned title words and title entities. To take a quick example, a news title may be: <i>\"Trump to deliver State of the Union address next week\"</i>, then the title words value may be `CandidateNews:34,45,334,23,12,987,3456,111,456,432` and the title entitie value may be: `entity:45,0,0,0,0,0,0,0,0,0`. Only the first value of entity vector is non-zero due to the word \"Trump\". The title value and entity value is hashed from 1 to `n` (where `n` is the number of distinct words or entities). Each feature length should be fixed at k (`doc_size` parameter), if the number of words in document is more than k, you should truncate the document to k words, and if the number of words in document is less than k, you should pad 0 to the end.\n",
    "the format is like: <br>\n",
    "`[Newsid] [w1,w2,w3...wk] [e1,e2,e3...ek]`\n",
    "\n",
    "- **word embedding/entity embedding/ context embedding files**: These are `*.npy` files of pretrained embeddings. After loading, each file is a `[n+1,k]` two-dimensional matrix, n is the number of words(or entities) of their hash dictionary, k is dimension of the embedding, note that we keep embedding 0 for zero padding.\n",
    "\n",
    "In this experiment, we used GloVe\\[4\\] vectors to initialize the word embedding. We trained entity embedding using TransE\\[2\\] on knowledge graph and context embedding is the average of the entity's neighbors in the knowledge graph.<br>\n",
    "\n",
    "## MIND dataset\n",
    "\n",
    "MIND dataset\\[3\\] is a large-scale English news dataset. It was collected from anonymized behavior logs of Microsoft News website. MIND contains 1,000,000 users, 161,013 news articles and 15,777,377 impression logs. Every news article contains rich textual content including title, abstract, body, category and entities. Each impression log contains the click events, non-clicked events and historical news click behaviors of this user before this impression.\n",
    "\n",
    "A smaller version, [MIND-small](https://azure.microsoft.com/en-us/services/open-datasets/catalog/microsoft-news-dataset/), is a small version of the MIND dataset by randomly sampling 50,000 users and their behavior logs from the MIND dataset.\n",
    "\n",
    "The datasets contains these files for both training and validation data:\n",
    "\n",
    "#### behaviors.tsv\n",
    "\n",
    "The behaviors.tsv file contains the impression logs and users' news click hostories. It has 5 columns divided by the tab symbol:\n",
    "\n",
    "+ Impression ID. The ID of an impression.\n",
    "+ User ID. The anonymous ID of a user.\n",
    "+ Time. The impression time with format \"MM/DD/YYYY HH:MM:SS AM/PM\".\n",
    "+ History. The news click history (ID list of clicked news) of this user before this impression.\n",
    "+ Impressions. List of news displayed in this impression and user's click behaviors on them (1 for click and 0 for non-click).\n",
    "\n",
    "One simple example:\n",
    "\n",
    "`1    U82271    11/11/2019 3:28:58 PM    N3130 N11621 N12917 N4574 N12140 N9748    N13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0 `\n",
    "\n",
    "#### news.tsv\n",
    "\n",
    "The news.tsv file contains the detailed information of news articles involved in the behaviors.tsv file. It has 7 columns, which are divided by the tab symbol:\n",
    "\n",
    "+ News ID\n",
    "+ Category\n",
    "+ SubCategory\n",
    "+ Title\n",
    "+ Abstract\n",
    "+ URL\n",
    "+ Title Entities (entities contained in the title of this news)\n",
    "+ Abstract Entities (entites contained in the abstract of this news)\n",
    "\n",
    "One simple example:\n",
    "\n",
    "`N46466    lifestyle    lifestyleroyals    The Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By    Shop the notebooks, jackets, and more that the royals can't live without.    https://www.msn.com/en-us/lifestyle/lifestyleroyals/the-brands-queen-elizabeth,-prince-charles,-and-prince-philip-swear-by/ss-AAGH0ET?ocid=chopendata    [{\"Label\": \"Prince Philip, Duke of Edinburgh\", \"Type\": \"P\", \"WikidataId\": \"Q80976\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [48], \"SurfaceForms\": [\"Prince Philip\"]}, {\"Label\": \"Charles, Prince of Wales\", \"Type\": \"P\", \"WikidataId\": \"Q43274\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [28], \"SurfaceForms\": [\"Prince Charles\"]}, {\"Label\": \"Elizabeth II\", \"Type\": \"P\", \"WikidataId\": \"Q9682\", \"Confidence\": 0.97, \"OccurrenceOffsets\": [11], \"SurfaceForms\": [\"Queen Elizabeth\"]}]    [] `\n",
    "\n",
    "#### entity_embedding.vec & relation_embedding.vec\n",
    "\n",
    "The entity_embedding.vec and relation_embedding.vec files contain the 100-dimensional embeddings of the entities and relations learned from the subgraph (from WikiData knowledge graph) by TransE method. In both files, the first column is the ID of entity/relation, and the other columns are the embedding vector values.\n",
    "\n",
    "One simple example:\n",
    "\n",
    "`Q42306013  0.014516 -0.106958 0.024590 ... -0.080382`\n",
    "\n",
    "\n",
    "## DKN architecture\n",
    "\n",
    "The following figure shows the architecture of DKN.\n",
    "\n",
    "![](https://recodatasets.z20.web.core.windows.net/images/dkn_architecture.png)\n",
    "\n",
    "DKN takes one piece of candidate news and one piece of a users clicked news as input. For each piece of news, a specially designed KCNN is used to process its title and generate an embedding vector. KCNN is an extension of traditional CNN that allows flexibility in incorporating symbolic knowledge from a knowledge graph into sentence representation learning.\n",
    "\n",
    "With the KCNN, we obtain a set of embedding vectors for a users clicked history. To get final embedding of the user with\n",
    "respect to the current candidate news, we use an attention-based method to automatically match the candidate news to each piece\n",
    "of his clicked news, and aggregate the users historical interests with different weights. The candidate news embedding and the user embedding are concatenated and fed into a deep neural network (DNN) to calculate the predicted probability that the user will click the candidate news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05340067",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df25eb37",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1106646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 16:23:29.069386: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 16:23:29.069450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 16:23:29.070601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-08 16:23:29.078066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 16:23:30.408874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]\n",
      "Tensorflow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from time import time\n",
    "import polars as pl\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "LOG = logging.getLogger(__name__)\n",
    "LOG.setLevel(logging.INFO)\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from recommenders.datasets.download_utils import maybe_download\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
    "from recommenders.models.deeprec.models.dkn import DKN\n",
    "from recommenders.models.deeprec.io.dkn_iterator import DKNTextIterator\n",
    "\n",
    "from group_33.dkn import *\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4594dec3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:group_33.dkn:../shared/194.035-2024S/groups/Gruppe_33/Group_33/data/small\n",
      "INFO:group_33.dkn:../tmp/dkn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# DKN parameters\n",
    "epochs = 10\n",
    "history_size = 50\n",
    "batch_size = 1000\n",
    "\n",
    "DATASET_NAME = \"small\" # one of: demo, small, large\n",
    "GROUP_PATH = Path(\"../shared/194.035-2024S/groups/Gruppe_33/Group_33\")\n",
    "\n",
    "\n",
    "# prepare tmp dir\n",
    "tmp_path = Path(\"..\", \"tmp\", \"dkn\")\n",
    "tmp_data_path = tmp_path / DATASET_NAME\n",
    "(tmp_data_path / \"validation\").mkdir(exist_ok=True, parents=True)\n",
    "(tmp_data_path / \"train\").mkdir(exist_ok=True, parents=True)\n",
    "(tmp_data_path / \"evaluation\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "tmp_test_path = tmp_path / \"test\"\n",
    "tmp_test_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# train & validation & evaluation\n",
    "data_path = GROUP_PATH / \"data\" / DATASET_NAME\n",
    "train_file = tmp_data_path / \"train\" / \"behaviours.txt\"\n",
    "valid_file = tmp_data_path / \"validation\" / \"behaviours.txt\"\n",
    "evaluation_file = tmp_data_path / \"evaluation\" / \"behaviors.txt\"\n",
    "user_history_file = tmp_data_path / \"user_history.txt\"\n",
    "articles_file = data_path / \"articles.parquet\"\n",
    "articles_tokenized_file = tmp_data_path / \"articles_tokenized.parquet\"\n",
    "word_embeddings_file = tmp_data_path / \"word_embeddings.npy\"\n",
    "entity_embeddings_file = tmp_data_path / \"entity_embeddings.npy\"\n",
    "context_embeddings_file = tmp_data_path / \"context_embeddings.npy\"\n",
    "news_feature_file = tmp_data_path / \"news_feature.txt\"\n",
    "infer_embedding_file = tmp_data_path / \"infer_embedding.txt\"\n",
    "\n",
    "# test\n",
    "test_raw_file = data_path / \"..\" / \"ebnerd_testset\" / \"test\" / \"behaviors.parquet\"\n",
    "test_file = tmp_test_path / \"behavior.txt\"\n",
    "test_articles_file = GROUP_PATH / \"data\" / \"test\" / \"articles.parquet\"\n",
    "test_articles_tokenized_file = tmp_test_path / \"articles_tokenized.parquet\"\n",
    "\n",
    "# prediction\n",
    "indexed_behaviors_file = tmp_data_path / \"indexed_behaviors.parquet\"\n",
    "scores_file = tmp_data_path / \"scores.txt\"\n",
    "predictions_file = tmp_data_path / \"predictions.txt\"\n",
    "\n",
    "LOG.info(data_path)\n",
    "LOG.info(tmp_path)\n",
    "\n",
    "pl.Config.set_tbl_rows(100)\n",
    "\n",
    "run_train = True if os.environ.get(\"TRAIN\") else False\n",
    "print(run_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37110c1a",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "In this example, let's go through a real case on how to apply DKN on a raw news dataset from the very beginning. We will download a copy of open-source MIND dataset, in its original raw format. Then we will process the raw data files into DKN's input data format, which is stated previously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4a48a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.08683494e+00,  1.00016955e+00,  5.65126327e-01, -1.18931012e-01,\n",
       "        4.29616674e-01,  6.04400804e-01, -1.76152259e-01,  2.30443105e-01,\n",
       "        2.69060423e-02,  1.90025512e-01,  5.58039486e-02, -3.05032716e-01,\n",
       "        7.14906749e-01, -1.30265762e-01,  5.02504432e-01,  1.45054273e+00,\n",
       "        4.83627211e-02, -3.23556334e-01, -5.30043628e-01, -1.10440839e+00,\n",
       "       -9.31051620e-01, -6.29733293e-01, -8.72917512e-01,  1.29576482e+00,\n",
       "        8.90542467e-01,  1.53463695e-01,  4.87522537e-02, -4.03002256e-01,\n",
       "       -4.29287135e-01, -6.67051489e-01, -1.38137103e-01, -8.26372647e-01,\n",
       "       -2.51646338e-01,  2.54731861e-02, -3.92829812e-01,  8.01710678e-01,\n",
       "        4.68979134e-01, -1.37049981e-01, -5.95778783e-01, -6.10334950e-02,\n",
       "        4.29620545e-01, -9.37379515e-01, -6.25330604e-01, -7.16531807e-01,\n",
       "       -9.62215591e-02, -1.02356705e-01, -4.54664016e-01,  3.51949342e-01,\n",
       "       -3.81492264e-01, -1.60995698e-01,  1.22625123e-01,  4.72695653e-01,\n",
       "       -2.55172412e-01,  3.10049392e-01, -5.45093138e-01, -1.65311139e-01,\n",
       "        6.85248397e-02,  6.03359769e-01, -4.08635548e-01,  7.22764792e-01,\n",
       "       -8.61239981e-01, -2.35525583e-02,  5.27697640e-01,  6.53886153e-01,\n",
       "        6.83844787e-02, -2.64605230e-01, -5.02012355e-01, -3.50760812e-02,\n",
       "       -1.34017079e-01,  3.23464368e-01, -6.42972706e-01,  1.62213884e-01,\n",
       "       -1.24497468e-03, -4.86900895e-01,  3.47018236e-01,  4.52409301e-01,\n",
       "        8.20603810e-01,  6.36925674e-01,  7.34952673e-01, -7.60126836e-01,\n",
       "        3.71480766e-01,  1.72028522e-02, -2.50120614e-01, -2.29021536e-01,\n",
       "       -4.44611192e-01,  1.64663034e-01,  2.27833070e-01,  9.54940650e-01,\n",
       "       -3.83334285e-01,  6.06125085e-03, -9.32341002e-02, -5.47233926e-01,\n",
       "        3.68458727e-01,  1.69108814e-01,  4.66022200e-01,  9.59026465e-01,\n",
       "       -8.45509374e-02,  8.15283535e-01,  6.22652022e-01,  1.08781579e-01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_context_embedding(\"Q35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96269eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (tmp_path / \"model.bin\").exists():\n",
    "    maybe_download(\"http://vectors.nlpl.eu/repository/20/38.zip\", tmp_path / \"word2vec.zip\")\n",
    "\n",
    "    with zipfile.ZipFile(tmp_path / \"word2vec.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dafe10",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:group_33.dkn:Starting tokenize_articles for input file: ../shared/194.035-2024S/groups/Gruppe_33/Group_33/data/test/articles.parquet\n",
      "/opt/conda/lib/python3.11/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'da_dacy_large_trf' (0.2.0) was trained with spaCy v3.5.2 and may not be 100% compatible with the current version (3.7.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/spacy_transformers/layers/hf_shim.py:137: UserWarning: Error loading saved torch state_dict with strict=True, likely due to differences between 'transformers' versions. Attempting to load with strict=False as a fallback...\n",
      "\n",
      "If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current 'transformers' and 'spacy-transformers' versions. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/e11908553/Group_33/src/group_33/dkn.py:111: PolarsInefficientMapWarning: \n",
      "Expr.map_elements is significantly slower than the native expressions API.\n",
      "Only use if you absolutely CANNOT implement your logic otherwise.\n",
      "Replace this expression...\n",
      "  - pl.col(\"title\").map_elements(lambda title: ...)\n",
      "with this one instead:\n",
      "  + pl.col(\"title\") | ' '\n",
      "\n",
      "  .map_elements(lambda title: title or \" \")\n"
     ]
    }
   ],
   "source": [
    "from group_33.util import train_test_split\n",
    "pl.Config.set_streaming_chunk_size(500_000)\n",
    "force_reload = False\n",
    "\n",
    "if not train_file.exists() or force_reload:\n",
    "    train = transform_behaviors(pl.scan_parquet(data_path / 'train' / 'behaviors.parquet'))\n",
    "    train.sink_csv(train_file, separator=' ', quote_style='never', include_header=False)\n",
    "    # train_test.collect(streaming=True).write_csv(valid_file, separator=' ', quote_style='never', include_header=False)\n",
    "\n",
    "if not evaluation_file.exists() or force_reload:\n",
    "    validation_behaviors = pl.scan_parquet(data_path / 'validation' / 'behaviors.parquet')\n",
    "    validation, evaluation = train_test_split(validation_behaviors, 0.5)\n",
    "\n",
    "    validation_transformed = transform_behaviors(validation)\n",
    "    validation_transformed.collect(streaming=True).write_csv(evaluation_file, separator=' ', quote_style='never', include_header=False)\n",
    "\n",
    "    evaluation_transformed = transform_behaviors(evaluation)\n",
    "    evaluation_transformed.collect(streaming=True).write_csv(valid_file, separator=' ', quote_style='never', include_header=False)\n",
    "\n",
    "if not user_history_file.exists() or force_reload:\n",
    "    user_history = transform_history(\n",
    "        data_path / 'train' / 'history.parquet',\n",
    "        data_path / 'validation' / 'history.parquet',\n",
    "        data_path / '..' / 'ebnerd_testset' / 'test' / 'history.parquet'\n",
    "    )\n",
    "    user_history.sink_csv(user_history_file, separator=' ', quote_style='never', include_header=False)\n",
    "\n",
    "if not articles_tokenized_file.exists() or force_reload:\n",
    "    tokenize_articles(articles_file, articles_tokenized_file)\n",
    "\n",
    "if not test_articles_tokenized_file.exists() or force_reload:\n",
    "    tokenize_articles(test_articles_file, test_articles_tokenized_file)\n",
    "\n",
    "if not news_feature_file.exists() or force_reload:\n",
    "    create_feature_file(\n",
    "        tmp_path / \"model.bin\",\n",
    "        articles_tokenized_file, test_articles_tokenized_file,\n",
    "        word_embeddings_file, entity_embeddings_file,\n",
    "        context_embeddings_file, news_feature_file, 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d96ceba",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = maybe_download(url=\"https://recodatasets.z20.web.core.windows.net/deeprec/deeprec/dkn/dkn_MINDsmall.yaml\",\n",
    "                           work_directory=data_path)\n",
    "hparams = prepare_hparams(yaml_file,\n",
    "                          seed=33,\n",
    "                          show_step=100,\n",
    "                          news_feature_file=news_feature_file.as_posix(),\n",
    "                          user_history_file=user_history_file.as_posix(),\n",
    "                          wordEmb_file=word_embeddings_file.as_posix(),\n",
    "                          entityEmb_file=entity_embeddings_file.as_posix(),\n",
    "                          contextEmb_file=context_embeddings_file.as_posix(),\n",
    "                          epochs=epochs,\n",
    "                          save_model=True,\n",
    "                          MODEL_DIR=(tmp_path / \"model\" / f\"{int(time())}_e{epochs}_h{history_size}\").as_posix(),\n",
    "                          history_size=history_size,\n",
    "                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30eebf3",
   "metadata": {},
   "source": [
    "## Train the DKN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fe3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DKN(hparams, DKNTextIterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006ce52",
   "metadata": {},
   "source": [
    "small:   2_585_747\n",
    "large: 133_810_641\n",
    "--> factor of 51 between small & large\n",
    "\n",
    "on small:\n",
    "    batch 1000 -> 2600 steps\n",
    "    hist 50\n",
    "    takes 50 min / epoch\n",
    "\n",
    "on small:\n",
    "    batch 1000\n",
    "    hist 5\n",
    "    takes 10 min / epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a04b98",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    model.fit(train_file, valid_file)\n",
    "else:\n",
    "    model.load_model(\"../tmp/model/epoch_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124a8e1",
   "metadata": {},
   "source": [
    "## Evaluate the DKN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5b5a3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "res = model.run_eval(str(evaluation_file))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386b63e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Predict for RecSys Challenge Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not Path(test_file).exists():\n",
    "    transform_behaviors_test(str(test_raw_file), indexed_behaviors_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(str(test_file), scores_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220795b4",
   "metadata": {},
   "source": [
    "Index the raw data to make reconstructing the original order of test samples possible for the predicitons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6044bf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_rankings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# combine scores with impression id\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rankings \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_rankings\u001b[49m(test_raw_file, indexed_behaviors_file, scores_file)\n\u001b[1;32m      3\u001b[0m rankings\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39mcollect(streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_rankings' is not defined"
     ]
    }
   ],
   "source": [
    "# combine scores with impression id\n",
    "rankings = calculate_rankings(indexed_behaviors_file, scores_file)\n",
    "rankings.write_csv(predictions_file, separator=\" \", include_header=False)\n",
    "print(f\"Created predictions file at {predictions_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e37740",
   "metadata": {},
   "source": [
    "Sort the rankings by the original order (given by the index) and persist the resulting rankings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7abc79",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Check if produced prediction matches with original impression row order\n",
    "# (pl.scan_parquet(test_raw_file)\n",
    "#     .select(\"impression_id\", \"article_ids_inview\")\n",
    "#     .with_row_index()\n",
    "#     .with_columns(pl.col(\"article_ids_inview\").map_elements(lambda el: len(el)).alias(\"len_a_ids\"))\n",
    "#    # .filter(pl.col(\"impression_id\") == 0)\n",
    "# ).collect().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = (pl.scan_csv(test_file, has_header=False, separator=' ')\n",
    "#     .filter(pl.col(\"column_3\").str.contains(\"6451383\"))\n",
    "# \n",
    "# )\n",
    "#     \n",
    "# d.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30d71a",
   "metadata": {},
   "source": [
    "## Document embedding inference API\n",
    "\n",
    "After training, you can get document embedding through this document embedding inference API. The input file format is same with document feature file. The output file fomrat is: `[Newsid] [embedding]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_get_embedding(news_feature_file, infer_embedding_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80dc82a",
   "metadata": {},
   "source": [
    "## Results on large MIND dataset\n",
    "\n",
    "Here are performances using the large MIND dataset (1,000,000 users, 161,013 news articles and 15,777,377 impression logs).\n",
    "\n",
    "| Models | g-AUC | MRR |NDCG@5 | NDCG@10 |\n",
    "| :------| :------: | :------: | :------: | :------ |\n",
    "| LibFM | 0.5993 | 0.2823 | 0.3005 | 0.3574 |\n",
    "| Wide&Deep | 0.6216 | 0.2931 | 0.3138 | 0.3712 |\n",
    "| DKN | 0.6436 | 0.3128 | 0.3371 | 0.3908|\n",
    "\n",
    "\n",
    "Note that the results of DKN are using Microsoft recommender and the results of the first two models come from the MIND paper \\[3\\].\n",
    "We compare the results on the same test dataset.\n",
    "\n",
    "One epoch takes 6381.3s (5066.6s for training, 1314.7s for evaluating) for DKN on GPU. Hardware specification for running the large dataset: <br>\n",
    "GPU: Tesla P100-PCIE-16GB <br>\n",
    "CPU: 6 cores Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6afdc",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\\[1\\] Hongwei Wang, Fuzheng Zhang, Xing Xie and Minyi Guo, \"DKN: Deep Knowledge-Aware Network for News Recommendation\", in Proceedings of the 2018 World Wide Web Conference (WWW), 2018, https://arxiv.org/abs/1801.08284. <br>\n",
    "\\[2\\] Knowledge Graph Embeddings including TransE, TransH, TransR and PTransE. https://github.com/thunlp/KB2E <br>\n",
    "\\[3\\] Fangzhao Wu et al., \"MIND: A Large-scale Dataset for News Recommendation\", Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, https://msnews.github.io/competition.html. <br>\n",
    "\\[4\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
