{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b598b21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# DKN : Deep Knowledge-Aware Network for News Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05340067",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from time import time\n",
    "import polars as pl\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "LOG = logging.getLogger(__name__)\n",
    "LOG.setLevel(logging.INFO)\n",
    "\n",
    "from recommenders.datasets.download_utils import maybe_download\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
    "from recommenders.models.deeprec.models.dkn import DKN\n",
    "from recommenders.models.deeprec.io.dkn_iterator import DKNTextIterator\n",
    "\n",
    "from group_33.util import train_test_split\n",
    "from group_33.dkn import transform_behaviors, transform_history, tokenize_articles, create_feature_file, transform_behaviors_test, calculate_rankings\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594dec3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DKN parameters\n",
    "epochs = 10\n",
    "history_size = 50\n",
    "batch_size = 1000\n",
    "\n",
    "DATASET_NAME = \"small\" # one of: demo, small, large\n",
    "GROUP_PATH = Path(\"../shared/194.035-2024S/groups/Gruppe_33/Group_33\")\n",
    "\n",
    "\n",
    "# prepare tmp dir\n",
    "tmp_path = GROUP_PATH / \"tmp\" / \"dkn\" #Path(\"..\", \"tmp\", \"dkn\")\n",
    "tmp_data_path = tmp_path / DATASET_NAME\n",
    "(tmp_data_path / \"validation\").mkdir(exist_ok=True, parents=True)\n",
    "(tmp_data_path / \"train\").mkdir(exist_ok=True, parents=True)\n",
    "(tmp_data_path / \"evaluation\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "tmp_test_path = tmp_path / \"test\"\n",
    "tmp_test_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# train & validation & evaluation\n",
    "data_path = GROUP_PATH / \"data\" / DATASET_NAME\n",
    "train_file = tmp_data_path / \"train\" / \"behaviours.txt\"\n",
    "valid_file = tmp_data_path / \"validation\" / \"behaviours.txt\"\n",
    "evaluation_file = tmp_data_path / \"evaluation\" / \"behaviors.txt\"\n",
    "user_history_file = tmp_data_path / \"user_history.txt\"\n",
    "articles_file = data_path / \"articles.parquet\"\n",
    "articles_tokenized_file = tmp_data_path / \"articles_tokenized.parquet\"\n",
    "word_embeddings_file = tmp_data_path / \"word_embeddings.npy\"\n",
    "entity_embeddings_file = tmp_data_path / \"entity_embeddings.npy\"\n",
    "context_embeddings_file = tmp_data_path / \"context_embeddings.npy\"\n",
    "news_feature_file = tmp_data_path / \"news_feature.txt\"\n",
    "infer_embedding_file = tmp_data_path / \"infer_embedding.txt\"\n",
    "\n",
    "# test\n",
    "test_raw_file = data_path / \"..\" / \"ebnerd_testset\" / \"test\" / \"behaviors.parquet\"\n",
    "test_file = tmp_test_path / \"behavior.txt\"\n",
    "test_articles_file = GROUP_PATH / \"data\" / \"test\" / \"articles.parquet\"\n",
    "test_articles_tokenized_file = tmp_test_path / \"articles_tokenized.parquet\"\n",
    "\n",
    "# prediction\n",
    "indexed_behaviors_file = tmp_data_path / \"indexed_behaviors.parquet\"\n",
    "scores_file = tmp_data_path / \"scores.txt\"\n",
    "predictions_file = tmp_data_path / \"predictions.txt\"\n",
    "\n",
    "LOG.info(data_path)\n",
    "LOG.info(tmp_path)\n",
    "\n",
    "pl.Config.set_tbl_rows(100)\n",
    "\n",
    "run_train = True if os.environ.get(\"TRAIN\") else False\n",
    "print(run_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37110c1a",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96269eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (tmp_path / \"model.bin\").exists():\n",
    "    maybe_download(\"http://vectors.nlpl.eu/repository/20/38.zip\", tmp_path / \"word2vec.zip\")\n",
    "\n",
    "    with zipfile.ZipFile(tmp_path / \"word2vec.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dafe10",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from group_33.util import train_test_split\n",
    "pl.Config.set_streaming_chunk_size(500_000)\n",
    "force_reload = False\n",
    "\n",
    "if not train_file.exists() or force_reload:\n",
    "    train = transform_behaviors(pl.scan_parquet(data_path / 'train' / 'behaviors.parquet'))\n",
    "    train.sink_csv(train_file, separator=' ', quote_style='never', include_header=False)\n",
    "    # train_test.collect(streaming=True).write_csv(valid_file, separator=' ', quote_style='never', include_header=False)\n",
    "\n",
    "if not evaluation_file.exists() or force_reload:\n",
    "    validation_behaviors = pl.scan_parquet(data_path / 'validation' / 'behaviors.parquet')\n",
    "    validation, evaluation = train_test_split(validation_behaviors, 0.5)\n",
    "\n",
    "    validation_transformed = transform_behaviors(validation)\n",
    "    validation_transformed.collect(streaming=True).write_csv(evaluation_file, separator=' ', quote_style='never', include_header=False)\n",
    "\n",
    "    evaluation_transformed = transform_behaviors(evaluation)\n",
    "    evaluation_transformed.collect(streaming=True).write_csv(valid_file, separator=' ', quote_style='never', include_header=False)\n",
    "\n",
    "if not user_history_file.exists() or force_reload:\n",
    "    user_history = transform_history(\n",
    "        data_path / 'train' / 'history.parquet',\n",
    "        data_path / 'validation' / 'history.parquet',\n",
    "        data_path / '..' / 'ebnerd_testset' / 'test' / 'history.parquet'\n",
    "    )\n",
    "    user_history.sink_csv(user_history_file, separator=' ', quote_style='never', include_header=False)\n",
    "\n",
    "if not articles_tokenized_file.exists() or force_reload:\n",
    "    tokenize_articles(articles_file, articles_tokenized_file)\n",
    "\n",
    "if not test_articles_tokenized_file.exists() or force_reload:\n",
    "    tokenize_articles(test_articles_file, test_articles_tokenized_file)\n",
    "\n",
    "if not news_feature_file.exists() or force_reload:\n",
    "    create_feature_file(\n",
    "        tmp_path / \"model.bin\",\n",
    "        articles_tokenized_file, test_articles_tokenized_file,\n",
    "        word_embeddings_file, entity_embeddings_file,\n",
    "        context_embeddings_file, news_feature_file, 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d96ceba",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c8e69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yaml_file = maybe_download(url=\"https://recodatasets.z20.web.core.windows.net/deeprec/deeprec/dkn/dkn_MINDsmall.yaml\",\n",
    "                           work_directory=data_path)\n",
    "hparams = prepare_hparams(yaml_file,\n",
    "                          seed=33,\n",
    "                          show_step=100,\n",
    "                          news_feature_file=news_feature_file.as_posix(),\n",
    "                          user_history_file=user_history_file.as_posix(),\n",
    "                          wordEmb_file=word_embeddings_file.as_posix(),\n",
    "                          entityEmb_file=entity_embeddings_file.as_posix(),\n",
    "                          contextEmb_file=context_embeddings_file.as_posix(),\n",
    "                          epochs=epochs,\n",
    "                          save_model=True,\n",
    "                          MODEL_DIR=(tmp_path / \"model\" / f\"{int(time())}_e{epochs}_h{history_size}\").as_posix(),\n",
    "                          history_size=history_size,\n",
    "                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30eebf3",
   "metadata": {},
   "source": [
    "## Train the DKN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fe3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DKN(hparams, DKNTextIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a04b98",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if run_train:\n",
    "    model.fit(train_file, valid_file)\n",
    "else:\n",
    "    model.load_model(str( GROUP_PATH / \"tmp/model/epoch_10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124a8e1",
   "metadata": {},
   "source": [
    "## Evaluate the DKN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5b5a3",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = model.run_eval(str(evaluation_file))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386b63e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Predict for RecSys Challenge Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(test_file).exists():\n",
    "    transform_behaviors_test(str(test_raw_file), indexed_behaviors_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(str(test_file), scores_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6044bf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "rankings = calculate_rankings(indexed_behaviors_file, scores_file)\n",
    "rankings.write_csv(predictions_file, separator=\" \", include_header=False)\n",
    "print(f\"Created predictions file at {predictions_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
