{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<i>Copyright (c) Recommenders contributors.</i>\n",
                "\n",
                "<i>Licensed under the MIT License.</i>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LSTUR: Neural News Recommendation with Long- and Short-term User Representations\n",
                "LSTUR \\[1\\] is a news recommendation approach capturing users' both long-term preferences and short-term interests. The core of LSTUR is a news encoder and a user encoder.  In the news encoder, we learn representations of news from their titles. In user encoder, we propose to learn long-term\n",
                "user representations from the embeddings of their IDs. In addition, we propose to learn short-term user representations from their recently browsed news via GRU network. Besides, we propose two methods to combine\n",
                "long-term and short-term user representations. The first one is using the long-term user representation to initialize the hidden state of the GRU network in short-term user representation. The second one is concatenating both\n",
                "long- and short-term user representations as a unified user vector.\n",
                "\n",
                "## Properties of LSTUR:\n",
                "- LSTUR captures users' both long-term and short term preference.\n",
                "- It uses embeddings of users' IDs to learn long-term user representations.\n",
                "- It uses users' recently browsed news via GRU network to learn short-term user representations.\n",
                "\n",
                "## Data format:\n",
                "For quicker training and evaluaiton, we sample MINDdemo dataset of 5k users from [MIND small dataset](https://msnews.github.io/). The MINDdemo dataset has the same file format as MINDsmall and MINDlarge. If you want to try experiments on MINDsmall and MINDlarge, please change the dowload source. Select the MIND_type parameter from ['large', 'small', 'demo'] to choose dataset.\n",
                " \n",
                "**MINDdemo_train** is used for training, and **MINDdemo_dev** is used for evaluation. Training data and evaluation data are composed of a news file and a behaviors file. You can find more detailed data description in [MIND repo](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md)\n",
                "\n",
                "### news data\n",
                "This file contains news information including newsid, category, subcatgory, news title, news abstarct, news url and entities in news title, entities in news abstarct.\n",
                "One simple example: <br>\n",
                "\n",
                "`N46466\tlifestyle\tlifestyleroyals\tThe Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\tShop the notebooks, jackets, and more that the royals can't live without.\thttps://www.msn.com/en-us/lifestyle/lifestyleroyals/the-brands-queen-elizabeth,-prince-charles,-and-prince-philip-swear-by/ss-AAGH0ET?ocid=chopendata\t[{\"Label\": \"Prince Philip, Duke of Edinburgh\", \"Type\": \"P\", \"WikidataId\": \"Q80976\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [48], \"SurfaceForms\": [\"Prince Philip\"]}, {\"Label\": \"Charles, Prince of Wales\", \"Type\": \"P\", \"WikidataId\": \"Q43274\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [28], \"SurfaceForms\": [\"Prince Charles\"]}, {\"Label\": \"Elizabeth II\", \"Type\": \"P\", \"WikidataId\": \"Q9682\", \"Confidence\": 0.97, \"OccurrenceOffsets\": [11], \"SurfaceForms\": [\"Queen Elizabeth\"]}]\t[]`\n",
                "<br>\n",
                "\n",
                "In general, each line in data file represents information of one piece of news: <br>\n",
                "\n",
                "`[News ID] [Category] [Subcategory] [News Title] [News Abstrct] [News Url] [Entities in News Title] [Entities in News Abstract] ...`\n",
                "\n",
                "<br>\n",
                "\n",
                "We generate a word_dict file to tranform words in news title to word indexes, and a embedding matrix is initted from pretrained glove embeddings.\n",
                "\n",
                "### behaviors data\n",
                "One simple example: <br>\n",
                "`1\tU82271\t11/11/2019 3:28:58 PM\tN3130 N11621 N12917 N4574 N12140 N9748\tN13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0`\n",
                "<br>\n",
                "\n",
                "In general, each line in data file represents one instance of an impression. The format is like: <br>\n",
                "\n",
                "`[Impression ID] [User ID] [Impression Time] [User Click History] [Impression News]`\n",
                "\n",
                "<br>\n",
                "\n",
                "User Click History is the user historical clicked news before Impression Time. Impression News is the displayed news in an impression, which format is:<br>\n",
                "\n",
                "`[News ID 1]-[label1] ... [News ID n]-[labeln]`\n",
                "\n",
                "<br>\n",
                "Label represents whether the news is clicked by the user. All information of news in User Click History and Impression News can be found in news data file."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Global settings and imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-06-15 09:15:55.366634: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2024-06-15 09:15:55.418846: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "2024-06-15 09:15:55.418918: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "2024-06-15 09:15:55.422216: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "2024-06-15 09:15:55.436548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2024-06-15 09:15:58.868150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "System version: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]\n",
                        "Tensorflow version: 2.15.1\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import numpy as np\n",
                "import zipfile\n",
                "from tqdm import tqdm\n",
                "from tempfile import TemporaryDirectory\n",
                "import tensorflow as tf\n",
                "tf.get_logger().setLevel('ERROR') # only show error messages\n",
                "\n",
                "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
                "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
                "from recommenders.models.newsrec.models.lstur import LSTURModel\n",
                "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
                "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
                "from recommenders.utils.notebook_utils import store_metadata\n",
                "\n",
                "print(\"System version: {}\".format(sys.version))\n",
                "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Prepare Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "epochs = 5\n",
                "seed = 40\n",
                "batch_size = 32\n",
                "\n",
                "# Options: demo, small, large\n",
                "MIND_type = \"demo\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Download and load data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 17.0k/17.0k [00:02<00:00, 6.42kKB/s]\n",
                        "100%|██████████| 9.84k/9.84k [00:01<00:00, 5.03kKB/s]\n",
                        "100%|██████████| 95.0k/95.0k [00:12<00:00, 7.41kKB/s]\n"
                    ]
                }
            ],
            "source": [
                "tmpdir = TemporaryDirectory()\n",
                "data_path = './tmp'\n",
                "\n",
                "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
                "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
                "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
                "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
                "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
                "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
                "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
                "yaml_file = os.path.join(data_path, \"utils\", r'lstur.yaml')\n",
                "\n",
                "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
                "\n",
                "if not os.path.exists(train_news_file):\n",
                "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
                "    \n",
                "if not os.path.exists(valid_news_file):\n",
                "    download_deeprec_resources(mind_url, \\\n",
                "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
                "if not os.path.exists(yaml_file):\n",
                "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
                "                               os.path.join(data_path, 'utils'), mind_utils)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "user_dict 50000\n"
                    ]
                }
            ],
            "source": [
                "import pickle as pkl\n",
                "\n",
                "with open(userDict_file, 'rb') as f:\n",
                "    user_dict = pkl.load(f)\n",
                "    print(\"user_dict\", len(user_dict))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create hyper-parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'./tmp/utils/uid2index.pkl'"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "userDict_file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "HParams object with values {'support_quick_scoring': True, 'dropout': 0.2, 'attention_hidden_dim': 200, 'head_num': 4, 'head_dim': 100, 'filter_num': 400, 'window_size': 3, 'vert_emb_dim': 100, 'subvert_emb_dim': 100, 'gru_unit': 400, 'type': 'ini', 'user_emb_dim': 50, 'learning_rate': 0.0001, 'optimizer': 'adam', 'epochs': 5, 'batch_size': 32, 'show_step': 100000, 'title_size': 30, 'his_size': 50, 'data_format': 'news', 'npratio': 4, 'metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'word_emb_dim': 300, 'cnn_activation': 'relu', 'model_type': 'lstur', 'loss': 'cross_entropy_loss', 'wordEmb_file': './tmp/utils/embedding.npy', 'wordDict_file': './tmp/utils/word_dict.pkl', 'userDict_file': './tmp/utils/uid2index.pkl'}\n"
                    ]
                }
            ],
            "source": [
                "hparams = prepare_hparams(yaml_file, \n",
                "                          wordEmb_file=wordEmb_file,\n",
                "                          wordDict_file=wordDict_file, \n",
                "                          userDict_file=userDict_file,\n",
                "                          batch_size=batch_size,\n",
                "                          epochs=epochs)\n",
                "print(hparams)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "iterator = MINDIterator"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train the LSTUR model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-06-15 09:16:27.949000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.021719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.023725: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.246437: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.248529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.250552: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.252455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 712 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
                        "2024-06-15 09:16:28.307324: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
                        "2024-06-15 09:16:28.328215: W tensorflow/c/c_api.cc:305] Operation '{name:'embedding/embeddings/Assign' id:27 op device:{requested: '', assigned: ''} def:{{{node embedding/embeddings/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](embedding/embeddings, embedding/embeddings/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
                        "2024-06-15 09:16:28.509212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.511384: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.513357: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.515688: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.517647: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.519551: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.521494: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.523360: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
                        "2024-06-15 09:16:28.525174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 712 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tensor(\"conv1d/Relu:0\", shape=(None, 30, 400), dtype=float32)\n",
                        "Tensor(\"att_layer2/Sum_1:0\", shape=(None, 400), dtype=float32)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/e11920555/recsys/lib/python3.11/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
                        "  super().__init__(name, **kwargs)\n"
                    ]
                }
            ],
            "source": [
                "model = LSTURModel(hparams, iterator, seed=seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "./tmp/valid/news.tsv ./tmp/valid/behaviors.tsv\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "0it [00:00, ?it/s]/home/e11920555/recsys/lib/python3.11/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
                        "  updates=self.state_updates,\n",
                        "2024-06-15 09:16:30.509357: W tensorflow/c/c_api.cc:305] Operation '{name:'gru/gru_cell/kernel/Assign' id:402 op device:{requested: '', assigned: ''} def:{{{node gru/gru_cell/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](gru/gru_cell/kernel, gru/gru_cell/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
                        "2024-06-15 09:16:30.945803: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
                        "2024-06-15 09:16:31.069319: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
                        "2024-06-15 09:16:31.214008: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:31.270296: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:31.322505: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
                        "586it [00:02, 275.88it/s]\n",
                        "0it [00:00, ?it/s]2024-06-15 09:16:32.491475: W tensorflow/c/c_api.cc:305] Operation '{name:'gru/strided_slice_2' id:954 op device:{requested: '', assigned: ''} def:{{{node gru/strided_slice_2}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, _has_manual_control_dependencies=true, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](gru/TensorArrayV2Stack/TensorListStack, gru/strided_slice_2/stack, gru/strided_slice_2/stack_1, gru/strided_slice_2/stack_2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
                        "2024-06-15 09:16:32.774967: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 145.55MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:32.834393: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 180.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:32.867641: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 180.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:32.867724: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 176.83MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:32.867757: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.20GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:32.936688: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 145.55MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:32.997882: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 180.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:33.030647: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 180.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
                        "2024-06-15 09:16:33.868831: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
                        "0it [00:02, ?it/s]\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(valid_news_file, valid_behaviors_file)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_news_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_behaviors_file\u001b[49m\u001b[43m)\u001b[49m)\n",
                        "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/recommenders/models/newsrec/models/base_model.py:328\u001b[0m, in \u001b[0;36mBaseModel.run_eval\u001b[0;34m(self, news_filename, behaviors_file)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the given file and returns some evaluation metrics.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    dict: A dictionary that contains evaluation metrics.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_quick_scoring:\n\u001b[0;32m--> 328\u001b[0m     _, group_labels, group_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_fast_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnews_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehaviors_file\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     _, group_labels, group_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_slow_eval(\n\u001b[1;32m    333\u001b[0m         news_filename, behaviors_file\n\u001b[1;32m    334\u001b[0m     )\n",
                        "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/recommenders/models/newsrec/models/base_model.py:402\u001b[0m, in \u001b[0;36mBaseModel.run_fast_eval\u001b[0;34m(self, news_filename, behaviors_file)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_fast_eval\u001b[39m(\u001b[38;5;28mself\u001b[39m, news_filename, behaviors_file):\n\u001b[1;32m    401\u001b[0m     news_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_news(news_filename)\n\u001b[0;32m--> 402\u001b[0m     user_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehaviors_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_vecs \u001b[38;5;241m=\u001b[39m news_vecs\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_vecs \u001b[38;5;241m=\u001b[39m user_vecs\n",
                        "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/recommenders/models/newsrec/models/base_model.py:361\u001b[0m, in \u001b[0;36mBaseModel.run_user\u001b[0;34m(self, news_filename, behaviors_file)\u001b[0m\n\u001b[1;32m    357\u001b[0m user_vecs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data_input \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_iterator\u001b[38;5;241m.\u001b[39mload_user_from_file(news_filename, behaviors_file)\n\u001b[1;32m    360\u001b[0m ):\n\u001b[0;32m--> 361\u001b[0m     user_index, user_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m     user_indexes\u001b[38;5;241m.\u001b[39mextend(np\u001b[38;5;241m.\u001b[39mreshape(user_index, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    363\u001b[0m     user_vecs\u001b[38;5;241m.\u001b[39mextend(user_vec)\n",
                        "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/recommenders/models/newsrec/models/base_model.py:340\u001b[0m, in \u001b[0;36mBaseModel.user\u001b[0;34m(self, batch_user_input)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muser\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_user_input):\n\u001b[1;32m    339\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_user_feature_from_iter(batch_user_input)\n\u001b[0;32m--> 340\u001b[0m     user_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muserencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     user_index \u001b[38;5;241m=\u001b[39m batch_user_input[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpr_index_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_index, user_vec\n",
                        "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/keras/src/engine/training_v1.py:1321\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(inputs)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_predict_function()\n\u001b[0;32m-> 1321\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
                        "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/keras/src/backend.py:4607\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4599\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4603\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[1;32m   4604\u001b[0m ):\n\u001b[1;32m   4605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 4607\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[1;32m   4609\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   4610\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[1;32m   4611\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[1;32m   4612\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4613\u001b[0m )\n",
                        "File \u001b[0;32m~/recsys/lib/python3.11/site-packages/tensorflow/python/client/session.py:1505\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1504\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1505\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1508\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1509\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "print(valid_news_file, valid_behaviors_file)\n",
                "print(model.run_eval(valid_news_file, valid_behaviors_file))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1086it [02:23,  7.55it/s]\n",
                        "586it [00:01, 430.29it/s]\n",
                        "236it [00:08, 28.16it/s]\n",
                        "7538it [00:01, 6738.86it/s]\n",
                        "1it [00:00,  7.26it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 1\n",
                        "train info: logloss loss:1.4868141242592814\n",
                        "eval info: group_auc:0.5973, mean_mrr:0.2622, ndcg@10:0.3501, ndcg@5:0.2861\n",
                        "at epoch 1 , train time: 143.8 eval time: 18.5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1086it [02:18,  7.85it/s]\n",
                        "586it [00:01, 455.05it/s]\n",
                        "236it [00:08, 28.32it/s]\n",
                        "7538it [00:01, 6669.92it/s]\n",
                        "1it [00:00,  8.64it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 2\n",
                        "train info: logloss loss:1.3999453176011916\n",
                        "eval info: group_auc:0.6219, mean_mrr:0.2803, ndcg@10:0.3726, ndcg@5:0.3099\n",
                        "at epoch 2 , train time: 138.3 eval time: 19.2\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1086it [02:18,  7.83it/s]\n",
                        "586it [00:01, 448.54it/s]\n",
                        "236it [00:08, 28.40it/s]\n",
                        "7538it [00:00, 8089.03it/s]\n",
                        "1it [00:00,  8.04it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 3\n",
                        "train info: logloss loss:1.3563778104044455\n",
                        "eval info: group_auc:0.6281, mean_mrr:0.285, ndcg@10:0.3785, ndcg@5:0.3159\n",
                        "at epoch 3 , train time: 138.7 eval time: 18.2\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1086it [02:18,  7.84it/s]\n",
                        "586it [00:01, 431.78it/s]\n",
                        "236it [00:08, 28.00it/s]\n",
                        "7538it [00:01, 7187.47it/s]\n",
                        "1it [00:00,  8.33it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 4\n",
                        "train info: logloss loss:1.3173029956786892\n",
                        "eval info: group_auc:0.6369, mean_mrr:0.2913, ndcg@10:0.3851, ndcg@5:0.3225\n",
                        "at epoch 4 , train time: 138.5 eval time: 18.5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1086it [02:18,  7.84it/s]\n",
                        "586it [00:01, 416.18it/s]\n",
                        "236it [00:08, 28.36it/s]\n",
                        "7538it [00:01, 7087.70it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 5\n",
                        "train info: logloss loss:1.2810899292017655\n",
                        "eval info: group_auc:0.6462, mean_mrr:0.3031, ndcg@10:0.3983, ndcg@5:0.3349\n",
                        "at epoch 5 , train time: 138.5 eval time: 18.4\n",
                        "CPU times: user 25min 40s, sys: 2min 21s, total: 28min 2s\n",
                        "Wall time: 13min 10s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<recommenders.models.newsrec.models.lstur.LSTURModel at 0x7f690ddf8b70>"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "586it [00:01, 440.26it/s]\n",
                        "236it [00:08, 28.51it/s]\n",
                        "7538it [00:00, 9166.73it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'group_auc': 0.6462, 'mean_mrr': 0.3031, 'ndcg@5': 0.3349, 'ndcg@10': 0.3983}\n",
                        "CPU times: user 37.1 s, sys: 2.69 s, total: 39.8 s\n",
                        "Wall time: 18.1 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
                "print(res_syn)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Record results for tests - ignore this cell\n",
                "store_metadata(\"group_auc\", res_syn['group_auc'])\n",
                "store_metadata(\"mean_mrr\", res_syn['mean_mrr'])\n",
                "store_metadata(\"ndcg@5\", res_syn['ndcg@5'])\n",
                "store_metadata(\"ndcg@10\", res_syn['ndcg@10'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_path = os.path.join(data_path, \"model\")\n",
                "os.makedirs(model_path, exist_ok=True)\n",
                "\n",
                "model.model.save_weights(os.path.join(model_path, \"lstur_ckpt\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Output Prediction File\n",
                "This code segment is used to generate the prediction.zip file, which is in the same format in [MIND Competition Submission Tutorial](https://competitions.codalab.org/competitions/24122#learn_the_details-submission-guidelines).\n",
                "\n",
                "Please change the `MIND_type` parameter to `large` if you want to submit your prediction to [MIND Competition](https://msnews.github.io/competition.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "586it [00:01, 438.04it/s]\n",
                        "236it [00:08, 28.26it/s]\n",
                        "7538it [00:00, 8876.72it/s]\n"
                    ]
                }
            ],
            "source": [
                "group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "7538it [00:00, 44730.54it/s]\n"
                    ]
                }
            ],
            "source": [
                "with open(os.path.join(data_path, 'prediction.txt'), 'w') as f:\n",
                "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
                "        impr_index += 1\n",
                "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
                "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
                "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
                "f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
                "f.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Reference\n",
                "\\[1\\] Mingxiao An, Fangzhao Wu, Chuhan Wu, Kun Zhang, Zheng Liu and Xing Xie: Neural News Recommendation with Long- and Short-term User Representations, ACL 2019<br>\n",
                "\\[2\\] Wu, Fangzhao, et al. \"MIND: A Large-scale Dataset for News Recommendation\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://msnews.github.io/competition.html <br>\n",
                "\\[3\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/"
            ]
        }
    ],
    "metadata": {
        "celltoolbar": "Tags",
        "interpreter": {
            "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
        },
        "kernelspec": {
            "display_name": "recsys",
            "language": "python",
            "name": "recsys"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
